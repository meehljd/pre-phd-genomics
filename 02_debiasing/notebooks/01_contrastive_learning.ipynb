{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Learning for Debiasing Genomic Embeddings\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements supervised contrastive learning to improve pre-computed genomic embeddings by reducing confounding effects from ancestry and technical variables while preserving discriminative signal for the outcome of interest.\n",
    "\n",
    "## Background\n",
    "\n",
    "Genomic data often contains confounding factors (ancestry, sequencing batch, read depth, etc.) that can lead to spurious associations in downstream analyses. Traditional approaches like linear regression adjustment or propensity score matching have limitations. Contrastive learning offers an alternative: learn an embedding space where:\n",
    "\n",
    "1. **Samples with the same phenotype** are pulled together (positive pairs)\n",
    "2. **Samples with different phenotypes** but matched confounders are pushed apart (negative pairs)\n",
    "3. **Confounder effects** are minimized through the matched design\n",
    "\n",
    "## Study Design\n",
    "\n",
    "We use a **matched case-control design** with:\n",
    "- Cases: Samples with `is_positive = 1`\n",
    "- Controls: 4 matched controls per case (matched on confounders)\n",
    "- Each case-control group is identified by `case_matched` column\n",
    "\n",
    "### Contrastive Pairs Definition\n",
    "\n",
    "- **Positive pairs**: Two samples with the same `is_positive` label AND same `case_matched` group\n",
    "- **Negative pairs**: Two samples with different `is_positive` labels AND same `case_matched` group\n",
    "\n",
    "This ensures we're learning to discriminate between cases and controls while being invariant to the confounders they share.\n",
    "\n",
    "## Training Strategy\n",
    "\n",
    "1. Split data by `case_matched` groups (20% validation) to prevent leakage\n",
    "2. Train a projection network using supervised contrastive loss\n",
    "3. Monitor progress using cluster separation and logistic regression AUC\n",
    "4. Compare embeddings before and after training using PCA visualizations\n",
    "\n",
    "## Expected Outcome\n",
    "\n",
    "The trained embeddings should:\n",
    "- ✓ Improve separation between cases and controls (higher AUC)\n",
    "- ✓ Reduce correlation with confounding variables\n",
    "- ✓ Maintain or improve downstream predictive performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, calinski_harabasz_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Load the parquet file containing pre-computed embeddings and metadata. The data should include:\n",
    "- **Embeddings**: Pre-computed feature vectors (e.g., from a variant autoencoder, PRS, or other genomic model)\n",
    "- **is_positive**: Binary outcome label (1 = case, 0 = control)\n",
    "- **case_matched**: Group ID linking each case to its matched controls\n",
    "- **Confounders**: Variables to control for (ancestry, batch, read depth, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/ext_meehl_joshua_mayo_edu/strand_cohort_eda/genomic/evals/data/embeddings/t1d/t1d_v1_emb_matrix_named.parquet\"\n",
    "meta_path = \"/home/ext_meehl_joshua_mayo_edu/strand_cohort_eda/genomic/evals/data/gsm/t1d/matched_has_diabetes1_v4_modified.csv\"\n",
    "cofound_path = \"/home/ext_meehl_joshua_mayo_edu/strand_cohort_eda/genomic/datasets/golden_benchmark/data/cohort_design/master_cohort.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2467, 51)\n",
      "\n",
      "Columns: ['sample_id', 'BACH2', 'C8A', 'C8B', 'CFH', 'CHRM3', 'CLEC16A', 'CTLA4', 'ERBB3', 'GLIS3', 'HLA-A-h1', 'HLA-A-h2', 'HLA-B-h1', 'HLA-B-h2', 'HLA-C-h1', 'HLA-C-h2', 'HLA-DPA1-h1', 'HLA-DPA1-h2', 'HLA-DPB1-h1', 'HLA-DPB1-h2', 'HLA-DQA1-h1', 'HLA-DQA1-h2', 'HLA-DQB1-h1', 'HLA-DQB1-h2', 'HLA-DRB1-h1', 'HLA-DRB1-h2', 'HLA-DRB3-h1', 'HLA-DRB3-h2', 'HLA-DRB4-h1', 'HLA-DRB4-h2', 'HLA-DRB5-h1', 'HLA-DRB5-h2', 'IFIH1', 'IGF2', 'IKZF4', 'IL2RA', 'IL2RB', 'INS', 'JAZF1', 'KCNQ1', 'NFIA', 'NLRP3', 'ORMDL3', 'PTPN22', 'RNLS', 'SH2B3', 'SIRPG', 'SLC30A8', 'TCF7L2', 'TH', 'UBASH3A']\n",
      "\n",
      "First few rows:\n"
     ]
    }
   ],
   "source": [
    "# Load the parquet file\n",
    "# UPDATE THIS PATH to your actual parquet file\n",
    "parquet_path = data_path\n",
    "df_emb = pd.read_parquet(parquet_path)\n",
    "\n",
    "print(f\"Dataset shape: {df_emb.shape}\")\n",
    "print(f\"\\nColumns: {df_emb.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "# df_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2467, 10)\n"
     ]
    }
   ],
   "source": [
    "df_meta = pd.read_csv(meta_path)\n",
    "df_meta['sample_id'] = df_meta['tap_kitid']\n",
    "mask = df_meta['sample_id'].isin(df_emb['sample_id'].unique())\n",
    "df_meta = df_meta[mask]\n",
    "print(df_meta.shape)\n",
    "# df_meta.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2467, 172)\n"
     ]
    }
   ],
   "source": [
    "df_conf = pd.read_csv(cofound_path)\n",
    "df_conf['sample_id'] = df_conf['tap_kitid']\n",
    "mask = df_conf['sample_id'].isin(df_emb['sample_id'].unique())\n",
    "df_conf = df_conf[mask]\n",
    "print(df_conf.shape)\n",
    "# df_conf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_cols = ['SIRPG', 'BACH2']\n",
    "cols = ['sample_id'] + embedding_cols\n",
    "df = df_emb[cols].copy()\n",
    "df = df.merge(df_meta, on='sample_id', how='left')\n",
    "df = df.merge(df_conf, on='sample_id', how='left')\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 embedding dimensions\n",
      "Embeddings shape: (2467, 2)\n"
     ]
    }
   ],
   "source": [
    "# Extract embedding columns (assume they start with 'emb_' or 'embedding_' or are numeric)\n",
    "# UPDATE THIS based on your column naming convention\n",
    "if len(embedding_cols) == 0:\n",
    "    # If no prefix, assume all numeric columns except known metadata are embeddings\n",
    "    metadata_cols = ['is_positive', 'case_matched', 'case_id']\n",
    "    embedding_cols = [col for col in df.select_dtypes(include=[np.number]).columns \n",
    "                     if col not in metadata_cols]\n",
    "\n",
    "print(f\"Found {len(embedding_cols)} embedding dimensions\")\n",
    "embeddings = df[embedding_cols].to_numpy()\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "# embeddings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2467, 2048)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = np.hstack([np.vstack(df[col].values) for col in embedding_cols])\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial PCA Analysis and Visualization\n",
    "\n",
    "Before training, we visualize the original embeddings using PCA to understand:\n",
    "1. How much variance is captured by PC1 and PC2\n",
    "2. Whether cases and controls are already separated\n",
    "3. How confounders correlate with the embedding space\n",
    "\n",
    "**Goal**: Identify if confounders are driving the main axes of variation, which would indicate bias that needs correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2467, 2048)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.28030056 0.22784619]\n",
      "Total variance explained: 0.508\n"
     ]
    }
   ],
   "source": [
    "# Perform PCA on original embeddings\n",
    "pca_original = PCA(n_components=2)\n",
    "pca_coords_original = pca_original.fit_transform(embeddings)\n",
    "\n",
    "# Add PCA coordinates to dataframe\n",
    "df['PC1_original'] = pca_coords_original[:, 0]\n",
    "df['PC2_original'] = pca_coords_original[:, 1]\n",
    "\n",
    "print(f\"Explained variance ratio: {pca_original.explained_variance_ratio_}\")\n",
    "print(f\"Total variance explained: {pca_original.explained_variance_ratio_.sum():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['ehr_ra_onset_date', 'ehr_first_mtx_date', 'tap_kitid_y',\n",
       "        'tap_state_enrolled', 'tap_state_current', 'exclude_from_all',\n",
       "        'exclude_from_train', 'mtx_response', 'sex_at_birth', 'ethnicity',\n",
       "        'is_hispanic', 'race', 'state_enroll', 'inferred_sex', 'is_female',\n",
       "        'gnomad_race', 'is_european', 'is_african', 'is_east_asian',\n",
       "        'is_other_race', 'currently_consented', 'age_at_sequence',\n",
       "        'is_gt_65_years', 'is_lt_40_years', 'is_lt_18_years',\n",
       "        'vcf_format_version', 'vcf_genome_version', 'vcf_assay_version',\n",
       "        'is_assay_v3', 'is_assay_v4', 'is_assay_v6', 'is_pretrain_kitid',\n",
       "        'pretrain_phase', 'is_in_long_range', 'is_in_short_range',\n",
       "        'is_gene_scale_pretrain', 'gene_scale_phase', 'ibd_list_id',\n",
       "        'tap_exclude_reason', 'is_prohibited', 'is_restricted',\n",
       "        'is_ra_not_reviewed', 'is_ra_invalid', 'is_region_south',\n",
       "        'is_region_east', 'is_region_west', 'is_region_midwest', 'has_ra',\n",
       "        'has_ibd', 'has_ibd_crohns'],\n",
       "       dtype='object'),\n",
       " ['bmi', 'is_bmi_lt_18', 'is_bmi_gt_30', 'is_bmi_gt_40'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[25:75], [col for col in df.columns if 'bmi' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confounder columns found: ['is_female', 'is_european', 'is_gt_65_years', 'vcf_assay_version', 'is_bmi_gt_30']\n"
     ]
    }
   ],
   "source": [
    "# Identify confounder columns (UPDATE THESE based on your data)\n",
    "# Examples: ancestry, batch, read_depth, sequencing_platform, etc.\n",
    "confounder_cols = [col for col in df.columns if col in [\n",
    "    'has_t1d', 'is_european', 'is_gt_65_years', 'vcf_assay_version', 'is_female', 'is_bmi_gt_30',  # Add your actual confounder column names\n",
    "]]\n",
    "\n",
    "print(f\"Confounder columns found: {confounder_cols}\")\n",
    "if len(confounder_cols) == 0:\n",
    "    print(\"WARNING: No confounder columns found. Please update the confounder_cols list above.\")\n",
    "    # Create dummy example for demonstration\n",
    "    confounder_cols = ['is_positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-plot visualization of PC1 and PC2 vs confounders\n",
    "show_plt = False\n",
    "\n",
    "if show_plt:\n",
    "\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    n_confounders = len(confounder_cols) + 1  # +1 for the main is_positive plot\n",
    "    n_cols = min(3, n_confounders)\n",
    "    n_rows = (n_confounders + n_cols - 1) // n_cols\n",
    "\n",
    "    # Use more contrasting colormaps\n",
    "    contrast_cmap = ListedColormap([\"#e41a1c\",\"#ffff33\", \"#377eb8\",]) # \"#4daf4a\", \"#984ea3\", \"#ff7f00\", \"#a65628\", \"#f781bf\", \"#999999\"])\n",
    "    contrast_cmap_cont = \"plasma\"  # For continuous variables\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 5*n_rows))\n",
    "    axes = axes.flatten() if n_confounders > 1 else [axes]\n",
    "\n",
    "    # Plot PC1 vs PC2 colored by is_positive (main outcome)\n",
    "    scatter = axes[0].scatter(df['PC1_original'], df['PC2_original'], \n",
    "                            c=df['is_positive'], cmap=contrast_cmap, \n",
    "                            alpha=0.7, s=30, edgecolor='k', linewidth=0.5)\n",
    "    axes[0].set_xlabel('PC1')\n",
    "    axes[0].set_ylabel('PC2')\n",
    "    axes[0].set_title('PC1 vs PC2 (Original) - Colored by is_positive')\n",
    "    axes[0].legend(*scatter.legend_elements(), title=\"is_positive\")\n",
    "\n",
    "    # Plot PC1 vs PC2 colored by each confounder\n",
    "    for idx, confounder in enumerate(confounder_cols, start=1):\n",
    "        if idx >= len(axes):\n",
    "            break\n",
    "        \n",
    "        # Check if confounder is categorical or continuous\n",
    "        if df[confounder].dtype == 'object' or df[confounder].nunique() < 10:\n",
    "            # Categorical - use discrete, high-contrast colors\n",
    "            scatter = axes[idx].scatter(df['PC1_original'], df['PC2_original'], \n",
    "                                    c=pd.Categorical(df[confounder]).codes, \n",
    "                                    cmap=contrast_cmap, alpha=0.25, s=30, edgecolor='k', linewidth=0.5)\n",
    "            axes[idx].legend(*scatter.legend_elements(), title=confounder, \n",
    "                            loc='best', fontsize=8)\n",
    "        else:\n",
    "            # Continuous - use a more vibrant colormap\n",
    "            scatter = axes[idx].scatter(df['PC1_original'], df['PC2_original'], \n",
    "                                    c=df[confounder], cmap=contrast_cmap_cont, \n",
    "                                    alpha=0.25, s=30, edgecolor='k', linewidth=0.5)\n",
    "            plt.colorbar(scatter, ax=axes[idx], label=confounder)\n",
    "        \n",
    "        axes[idx].set_xlabel('PC1')\n",
    "        axes[idx].set_ylabel('PC2')\n",
    "        axes[idx].set_title(f'PC1 vs PC2 (Original) - Colored by {confounder}')\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_confounders, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pca_original_confounders.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Validation Split\n",
    "\n",
    "**Critical**: We split by `case_matched` groups (not individual samples) to prevent data leakage.\n",
    "\n",
    "If we randomly split individuals, a case and its matched controls might end up in different sets, allowing the model to \"cheat\" by learning confounder patterns that appear in both train and validation.\n",
    "\n",
    "By keeping each case-control group together, we ensure the model generalizes to unseen confounder combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_only_mask = df['split'] == 'train'\n",
    "df = df[train_only_mask]\n",
    "\n",
    "missing_case_mask = df['matched_case_kitid'].isna()\n",
    "df.loc[missing_case_mask, 'matched_case_kitid'] = df.loc[missing_case_mask, 'sample_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 1408 samples (285 positive)\n",
      "Val set: 359 samples (72 positive)\n"
     ]
    }
   ],
   "source": [
    "# Recreate train/val splits by matched_case_kitid groups\n",
    "unique_groups = df['matched_case_kitid'].unique()\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_groups, val_groups = train_test_split(unique_groups, test_size=0.2, random_state=42)\n",
    "train_mask = df['matched_case_kitid'].isin(train_groups)\n",
    "val_mask = df['matched_case_kitid'].isin(val_groups)\n",
    "df_train = df[train_mask].copy()\n",
    "df_val = df[val_mask].copy()\n",
    "print(f\"Train set: {len(df_train)} samples ({df_train['is_positive'].sum()} positive)\")\n",
    "print(f\"Val set: {len(df_val)} samples ({df_val['is_positive'].sum()} positive)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(df, embedding_cols):\n",
    "    \"\"\"\n",
    "    Extract embeddings as a 2D numpy array (samples x embedding_dim).\n",
    "    Handles columns that are arrays/lists or flat values.\n",
    "    \"\"\"\n",
    "    # Check if all columns are scalar (float/int) for all rows\n",
    "    is_scalar = all(\n",
    "        df[col].map(lambda x: np.isscalar(x) or isinstance(x, (float, int))).all()\n",
    "        for col in embedding_cols\n",
    "    )\n",
    "    if is_scalar:\n",
    "        arr = df[embedding_cols].to_numpy(dtype=np.float32)\n",
    "    else:\n",
    "        arr = np.vstack([\n",
    "            np.concatenate([np.array(row[col]).ravel() for col in embedding_cols])\n",
    "            for _, row in df.iterrows()\n",
    "        ]).astype(np.float32)\n",
    "    if arr.ndim != 2:\n",
    "        arr = arr.reshape(arr.shape[0], -1)\n",
    "    return arr\n",
    "\n",
    "X_train = extract_embeddings(df_train, embedding_cols)\n",
    "y_train = df_train['is_positive'].values\n",
    "case_matched_train = pd.factorize(df_train['matched_case_kitid'])[0]\n",
    "\n",
    "X_val = extract_embeddings(df_val, embedding_cols)\n",
    "y_val = df_val['is_positive'].values\n",
    "case_matched_val = pd.factorize(df_val['matched_case_kitid'])[0]\n",
    "\n",
    "input_dim = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for each factor in case_matched_train:\n",
      "Counter({np.int64(0): 5, np.int64(1): 5, np.int64(2): 5, np.int64(3): 5, np.int64(4): 5, np.int64(5): 5, np.int64(6): 5, np.int64(7): 5, np.int64(8): 5, np.int64(9): 5, np.int64(10): 5, np.int64(11): 5, np.int64(12): 5, np.int64(13): 5, np.int64(14): 5, np.int64(15): 5, np.int64(16): 5, np.int64(17): 5, np.int64(18): 5, np.int64(19): 5, np.int64(20): 5, np.int64(21): 5, np.int64(22): 5, np.int64(23): 5, np.int64(24): 5, np.int64(25): 5, np.int64(26): 5, np.int64(27): 5, np.int64(28): 5, np.int64(29): 5, np.int64(30): 5, np.int64(31): 5, np.int64(32): 5, np.int64(33): 5, np.int64(34): 5, np.int64(35): 5, np.int64(36): 5, np.int64(37): 5, np.int64(38): 5, np.int64(39): 5, np.int64(41): 5, np.int64(42): 5, np.int64(43): 5, np.int64(44): 5, np.int64(45): 5, np.int64(46): 5, np.int64(47): 5, np.int64(48): 5, np.int64(49): 5, np.int64(50): 5, np.int64(51): 5, np.int64(52): 5, np.int64(53): 5, np.int64(54): 5, np.int64(55): 5, np.int64(56): 5, np.int64(57): 5, np.int64(58): 5, np.int64(59): 5, np.int64(60): 5, np.int64(61): 5, np.int64(62): 5, np.int64(63): 5, np.int64(64): 5, np.int64(65): 5, np.int64(66): 5, np.int64(67): 5, np.int64(68): 5, np.int64(69): 5, np.int64(70): 5, np.int64(71): 5, np.int64(72): 5, np.int64(73): 5, np.int64(74): 5, np.int64(75): 5, np.int64(76): 5, np.int64(77): 5, np.int64(78): 5, np.int64(79): 5, np.int64(80): 5, np.int64(81): 5, np.int64(82): 5, np.int64(83): 5, np.int64(84): 5, np.int64(85): 5, np.int64(86): 5, np.int64(87): 5, np.int64(88): 5, np.int64(89): 5, np.int64(90): 5, np.int64(91): 5, np.int64(92): 5, np.int64(93): 5, np.int64(94): 5, np.int64(95): 5, np.int64(96): 5, np.int64(97): 5, np.int64(98): 5, np.int64(99): 5, np.int64(100): 5, np.int64(101): 5, np.int64(102): 5, np.int64(103): 5, np.int64(104): 5, np.int64(105): 5, np.int64(106): 5, np.int64(107): 5, np.int64(108): 5, np.int64(109): 5, np.int64(110): 5, np.int64(111): 5, np.int64(112): 5, np.int64(113): 5, np.int64(114): 5, np.int64(115): 5, np.int64(116): 5, np.int64(117): 5, np.int64(118): 5, np.int64(119): 5, np.int64(120): 5, np.int64(121): 5, np.int64(122): 5, np.int64(123): 5, np.int64(124): 5, np.int64(125): 5, np.int64(126): 5, np.int64(127): 5, np.int64(128): 5, np.int64(129): 5, np.int64(130): 5, np.int64(131): 5, np.int64(132): 5, np.int64(133): 5, np.int64(134): 5, np.int64(135): 5, np.int64(136): 5, np.int64(137): 5, np.int64(138): 5, np.int64(139): 5, np.int64(140): 5, np.int64(141): 5, np.int64(142): 5, np.int64(143): 5, np.int64(146): 5, np.int64(147): 5, np.int64(148): 5, np.int64(149): 5, np.int64(150): 5, np.int64(151): 5, np.int64(152): 5, np.int64(153): 5, np.int64(154): 5, np.int64(155): 5, np.int64(156): 5, np.int64(157): 5, np.int64(158): 5, np.int64(159): 5, np.int64(160): 5, np.int64(161): 5, np.int64(162): 5, np.int64(163): 5, np.int64(164): 5, np.int64(165): 5, np.int64(166): 5, np.int64(167): 5, np.int64(168): 5, np.int64(169): 5, np.int64(170): 5, np.int64(171): 5, np.int64(172): 5, np.int64(173): 5, np.int64(174): 5, np.int64(175): 5, np.int64(176): 5, np.int64(177): 5, np.int64(178): 5, np.int64(179): 5, np.int64(180): 5, np.int64(181): 5, np.int64(182): 5, np.int64(183): 5, np.int64(184): 5, np.int64(185): 5, np.int64(186): 5, np.int64(187): 5, np.int64(188): 5, np.int64(189): 5, np.int64(190): 5, np.int64(191): 5, np.int64(192): 5, np.int64(193): 5, np.int64(194): 5, np.int64(195): 5, np.int64(196): 5, np.int64(197): 5, np.int64(198): 5, np.int64(199): 5, np.int64(200): 5, np.int64(201): 5, np.int64(202): 5, np.int64(203): 5, np.int64(204): 5, np.int64(205): 5, np.int64(206): 5, np.int64(207): 5, np.int64(208): 5, np.int64(209): 5, np.int64(210): 5, np.int64(212): 5, np.int64(213): 5, np.int64(214): 5, np.int64(215): 5, np.int64(216): 5, np.int64(217): 5, np.int64(218): 5, np.int64(219): 5, np.int64(220): 5, np.int64(221): 5, np.int64(222): 5, np.int64(223): 5, np.int64(224): 5, np.int64(225): 5, np.int64(226): 5, np.int64(227): 5, np.int64(229): 5, np.int64(230): 5, np.int64(231): 5, np.int64(232): 5, np.int64(233): 5, np.int64(234): 5, np.int64(235): 5, np.int64(236): 5, np.int64(237): 5, np.int64(238): 5, np.int64(239): 5, np.int64(240): 5, np.int64(241): 5, np.int64(242): 5, np.int64(243): 5, np.int64(245): 5, np.int64(246): 5, np.int64(247): 5, np.int64(248): 5, np.int64(249): 5, np.int64(250): 5, np.int64(251): 5, np.int64(252): 5, np.int64(253): 5, np.int64(254): 5, np.int64(255): 5, np.int64(256): 5, np.int64(257): 5, np.int64(258): 5, np.int64(259): 5, np.int64(260): 5, np.int64(261): 5, np.int64(262): 5, np.int64(263): 5, np.int64(264): 5, np.int64(265): 5, np.int64(266): 5, np.int64(267): 5, np.int64(268): 5, np.int64(269): 5, np.int64(270): 5, np.int64(271): 5, np.int64(272): 5, np.int64(273): 5, np.int64(274): 5, np.int64(275): 5, np.int64(276): 5, np.int64(277): 5, np.int64(278): 5, np.int64(279): 5, np.int64(280): 5, np.int64(281): 5, np.int64(282): 5, np.int64(283): 5, np.int64(284): 5, np.int64(145): 4, np.int64(40): 3, np.int64(144): 3, np.int64(211): 1, np.int64(228): 1, np.int64(244): 1})\n",
      "All factors have exactly 5 samples? False\n"
     ]
    }
   ],
   "source": [
    "# Check if each factor in case_matched_train has exactly 5 samples\n",
    "import collections\n",
    "factor_counts = collections.Counter(case_matched_train)\n",
    "print(\"Value counts for each factor in case_matched_train:\")\n",
    "print(factor_counts)\n",
    "all_five = all(count == 5 for count in factor_counts.values())\n",
    "print(f\"All factors have exactly 5 samples? {all_five}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PyTorch Contrastive Learning Architecture\n",
    "\n",
    "### ContrastiveProjector\n",
    "A 3-layer MLP that projects the input embeddings to a lower-dimensional space (128D) optimized for contrastive learning:\n",
    "- **BatchNorm**: Stabilizes training and prevents internal covariate shift\n",
    "- **Dropout**: Prevents overfitting to specific confounder patterns\n",
    "- **L2 Normalization**: Output embeddings lie on unit hypersphere, making cosine similarity meaningful\n",
    "\n",
    "### ContrastiveLoss\n",
    "Supervised contrastive loss adapted for matched case-control design:\n",
    "- Uses temperature-scaled cosine similarity\n",
    "- Only considers pairs within the same `case_matched` group\n",
    "- Pulls together samples with same label, pushes apart samples with different labels\n",
    "- Automatically handles variable numbers of positive pairs per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n",
      "ContrastiveProjector(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.1, inplace=False)\n",
      "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Total parameters: 100,480\n"
     ]
    }
   ],
   "source": [
    "class ContrastiveProjector(nn.Module):\n",
    "    \"\"\"\n",
    "    Projection network for contrastive learning.\n",
    "    Takes pre-computed embeddings and projects them to a lower-dimensional space\n",
    "    optimized for discriminating between positive and negative cases while\n",
    "    being invariant to confounders.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim=256, output_dim=128, dropout=0.1):\n",
    "        super(ContrastiveProjector, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.network(x), dim=1)  # L2 normalize for better contrastive learning\n",
    "\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Supervised contrastive loss for matched case-control design.\n",
    "    Positive pairs: same is_positive label AND same case_matched group\n",
    "    Negative pairs: different is_positive label AND same case_matched group (matched controls)\n",
    "    \"\"\"\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def forward(self, features, labels, case_matched):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: normalized embeddings, shape (batch_size, embed_dim)\n",
    "            labels: is_positive labels, shape (batch_size,)\n",
    "            case_matched: case_matched group IDs, shape (batch_size,)\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "        batch_size = features.shape[0]\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "        \n",
    "        # Create masks for positive and negative pairs\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        case_matched = case_matched.contiguous().view(-1, 1)\n",
    "        \n",
    "        # Positive mask: same label AND same case_matched group (but not same sample)\n",
    "        label_mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        case_mask = torch.eq(case_matched, case_matched.T).float().to(device)\n",
    "        positive_mask = label_mask * case_mask\n",
    "        positive_mask.fill_diagonal_(0)  # Exclude self-comparisons\n",
    "        \n",
    "        # Negative mask: different label AND same case_matched group\n",
    "        negative_mask = (1 - label_mask) * case_mask\n",
    "        \n",
    "        # For numerical stability\n",
    "        logits_max, _ = torch.max(similarity_matrix, dim=1, keepdim=True)\n",
    "        logits = similarity_matrix - logits_max.detach()\n",
    "        \n",
    "        # Compute log probabilities\n",
    "        exp_logits = torch.exp(logits) * (1 - torch.eye(batch_size).to(device))  # Exclude diagonal\n",
    "        \n",
    "        # Only consider negatives from same case_matched group\n",
    "        log_prob = logits - torch.log(torch.sum(exp_logits * (positive_mask + negative_mask + 1e-8), dim=1, keepdim=True))\n",
    "        \n",
    "        # Compute mean of log-likelihood over positive pairs\n",
    "        mean_log_prob_pos = (positive_mask * log_prob).sum(1) / (positive_mask.sum(1) + 1e-8)\n",
    "        \n",
    "        # Loss is negative log-likelihood\n",
    "        loss = -mean_log_prob_pos\n",
    "        loss = loss[positive_mask.sum(1) > 0].mean()  # Only compute loss for samples with positive pairs\n",
    "        \n",
    "        return loss\n",
    "\n",
    "# Initialize model\n",
    "input_dim = len(embedding_cols)\n",
    "model = ContrastiveProjector(input_dim=input_dim, hidden_dim=256, output_dim=128).to(device)\n",
    "criterion = ContrastiveLoss(temperature=0.07)\n",
    "\n",
    "print(f\"Model architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset and DataLoader\n",
    "\n",
    "PyTorch dataset wrapper for the embeddings with custom collation to pass:\n",
    "1. Pre-computed embeddings (input features)\n",
    "2. Labels (`is_positive`)\n",
    "3. Case-match group IDs (for contrastive loss computation)\n",
    "\n",
    "The DataLoader shuffles training data while keeping batches reasonably sized to ensure diverse case-control groups per batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 22\n",
      "Val batches: 6\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    \"\"\"Dataset for pre-computed embeddings with labels and case_matched groups\"\"\"\n",
    "    def __init__(self, embeddings, labels, case_matched):\n",
    "        self.embeddings = torch.FloatTensor(embeddings)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        self.case_matched = torch.LongTensor(case_matched)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx], self.case_matched[idx]\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = EmbeddingDataset(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    case_matched_train\n",
    ")\n",
    "\n",
    "val_dataset = EmbeddingDataset(\n",
    "    X_val, \n",
    "    y_val, \n",
    "    case_matched_val\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "# Use batch size that captures multiple cases with their controls (5 samples per case * batch)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Monitoring Functions\n",
    "\n",
    "We track two complementary metrics during training:\n",
    "\n",
    "### 1. Calinski-Harabasz Index (Geometric)\n",
    "Ratio of between-cluster variance to within-cluster variance. Higher values indicate better-defined, more separated clusters.\n",
    "- **Formula**: (BSS / WSS) × ((N - k) / (k - 1)) where N = samples, k = classes\n",
    "- **Advantage**: Fast, well-established, scale-invariant\n",
    "- **Range**: [0, ∞), higher is better\n",
    "\n",
    "### 2. Logistic Regression AUC (Discriminative)\n",
    "Train a simple linear classifier on the embeddings and evaluate on validation set.\n",
    "- **Advantage**: Measures actual downstream predictive utility\n",
    "- **Limitation**: May underestimate quality if embeddings require non-linear classifier\n",
    "\n",
    "By monitoring both metrics, we get a complete picture of embedding quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def compute_cluster_separation(embeddings, labels):\n",
    "    \"\"\"\n",
    "    Compute Calinski-Harabasz Index (Variance Ratio Criterion).\n",
    "    Measures the ratio of between-cluster to within-cluster variance.\n",
    "    Higher values indicate better-defined clusters.\n",
    "    \n",
    "    Returns:\n",
    "        float: CH index score (higher is better, range [0, inf))\n",
    "    \"\"\"\n",
    "    if len(np.unique(labels)) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    return calinski_harabasz_score(embeddings, labels)\n",
    "\n",
    "\n",
    "def compute_logistic_auc(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Train a logistic regression classifier and return validation AUC.\n",
    "    \"\"\"\n",
    "    clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    y_pred_proba = clf.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "\n",
    "def evaluate_embeddings(model, train_loader, val_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the quality of learned embeddings using cluster separation and AUC.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get all train embeddings\n",
    "    train_embeddings_list = []\n",
    "    train_labels_list = []\n",
    "    with torch.no_grad():\n",
    "        for embeddings, labels, _ in train_loader:\n",
    "            embeddings = embeddings.to(device)\n",
    "            projected = model(embeddings)\n",
    "            train_embeddings_list.append(projected.cpu().numpy())\n",
    "            train_labels_list.append(labels.numpy())\n",
    "    \n",
    "    train_embeddings = np.vstack(train_embeddings_list)\n",
    "    train_labels = np.concatenate(train_labels_list)\n",
    "    \n",
    "    # Get all val embeddings\n",
    "    val_embeddings_list = []\n",
    "    val_labels_list = []\n",
    "    with torch.no_grad():\n",
    "        for embeddings, labels, _ in val_loader:\n",
    "            embeddings = embeddings.to(device)\n",
    "            projected = model(embeddings)\n",
    "            val_embeddings_list.append(projected.cpu().numpy())\n",
    "            val_labels_list.append(labels.numpy())\n",
    "    \n",
    "    val_embeddings = np.vstack(val_embeddings_list)\n",
    "    val_labels = np.concatenate(val_labels_list)\n",
    "    \n",
    "    # Compute metrics\n",
    "    train_separation = compute_cluster_separation(train_embeddings, train_labels)\n",
    "    val_separation = compute_cluster_separation(val_embeddings, val_labels)\n",
    "    auc = compute_logistic_auc(train_embeddings, train_labels, val_embeddings, val_labels)\n",
    "    \n",
    "    return {\n",
    "        'train_separation': train_separation,\n",
    "        'val_separation': val_separation,\n",
    "        'val_auc': auc,\n",
    "        'train_embeddings': train_embeddings,\n",
    "        'train_labels': train_labels,\n",
    "        'val_embeddings': val_embeddings,\n",
    "        'val_labels': val_labels\n",
    "    }\n",
    "\n",
    "print(\"Monitoring functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Loop\n",
    "\n",
    "Train the projection network with:\n",
    "- **AdamW optimizer**: Decoupled weight decay for better generalization\n",
    "- **Cosine annealing schedule**: Gradually reduces learning rate for fine-tuning\n",
    "- **Evaluation every 5 epochs**: Track cluster separation and AUC without slowing training\n",
    "- **Best model selection**: Save model with highest validation AUC\n",
    "\n",
    "**Note**: Some batches may have NaN loss if they don't contain valid positive pairs. These are safely skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50 epochs...\n",
      "Initial evaluation before training:\n"
     ]
    }
   ],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_separation': [],\n",
    "    'val_separation': [],\n",
    "    'val_auc': []\n",
    "}\n",
    "\n",
    "print(f\"Training for {num_epochs} epochs...\")\n",
    "print(f\"Initial evaluation before training:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x2048 and 2x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Baseline evaluation (before training)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m baseline_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline - Train Separation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_separation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline - Val Separation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_separation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[34], line 42\u001b[0m, in \u001b[0;36mevaluate_embeddings\u001b[0;34m(model, train_loader, val_loader, device)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m embeddings, labels, _ \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     41\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 42\u001b[0m     projected \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     train_embeddings_list\u001b[38;5;241m.\u001b[39mappend(projected\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     44\u001b[0m     train_labels_list\u001b[38;5;241m.\u001b[39mappend(labels\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[32], line 23\u001b[0m, in \u001b[0;36mContrastiveProjector.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mnormalize(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x2048 and 2x256)"
     ]
    }
   ],
   "source": [
    "# Baseline evaluation (before training)\n",
    "baseline_metrics = evaluate_embeddings(model, train_loader, val_loader, device)\n",
    "print(f\"Baseline - Train Separation: {baseline_metrics['train_separation']:.4f}\")\n",
    "print(f\"Baseline - Val Separation: {baseline_metrics['val_separation']:.4f}\")\n",
    "print(f\"Baseline - Val AUC: {baseline_metrics['val_auc']:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 0/22 [00:00<?, ?it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x2048 and 2x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m case_matched \u001b[38;5;241m=\u001b[39m case_matched\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m projected \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(projected, labels, case_matched)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Skip if loss is nan (can happen if batch has no valid pairs)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[39], line 23\u001b[0m, in \u001b[0;36mContrastiveProjector.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mnormalize(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/pre-phd-genomics/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x2048 and 2x256)"
     ]
    }
   ],
   "source": [
    "# Main training loop\n",
    "best_val_auc = 0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_batches = 0\n",
    "    \n",
    "    for embeddings, labels, case_matched in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        embeddings = embeddings.to(device)\n",
    "        labels = labels.to(device)\n",
    "        case_matched = case_matched.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        projected = model(embeddings)\n",
    "        loss = criterion(projected, labels, case_matched)\n",
    "        \n",
    "        # Skip if loss is nan (can happen if batch has no valid pairs)\n",
    "        if torch.isnan(loss):\n",
    "            continue\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_batches += 1\n",
    "    \n",
    "    train_loss /= max(train_batches, 1)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for embeddings, labels, case_matched in val_loader:\n",
    "            embeddings = embeddings.to(device)\n",
    "            labels = labels.to(device)\n",
    "            case_matched = case_matched.to(device)\n",
    "            \n",
    "            projected = model(embeddings)\n",
    "            loss = criterion(projected, labels, case_matched)\n",
    "            \n",
    "            if not torch.isnan(loss):\n",
    "                val_loss += loss.item()\n",
    "                val_batches += 1\n",
    "    \n",
    "    val_loss /= max(val_batches, 1)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Evaluate embeddings quality every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        metrics = evaluate_embeddings(model, train_loader, val_loader, device)\n",
    "        \n",
    "        history['train_separation'].append(metrics['train_separation'])\n",
    "        history['val_separation'].append(metrics['val_separation'])\n",
    "        history['val_auc'].append(metrics['val_auc'])\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"  Train Sep: {metrics['train_separation']:.4f} | Val Sep: {metrics['val_separation']:.4f}\")\n",
    "        print(f\"  Val AUC: {metrics['val_auc']:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        # Save best model\n",
    "        if metrics['val_auc'] > best_val_auc:\n",
    "            best_val_auc = metrics['val_auc']\n",
    "            best_model_state = model.state_dict().copy()\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "print(f\"Training complete!\")\n",
    "print(f\"Best validation AUC: {best_val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"Loaded best model based on validation AUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training History Visualization\n",
    "\n",
    "Visualize three key metrics over training:\n",
    "\n",
    "1. **Contrastive Loss**: Should decrease and stabilize\n",
    "2. **Calinski-Harabasz Index**: Should increase as clusters become better separated\n",
    "3. **Validation AUC**: Should improve, indicating better downstream utility\n",
    "\n",
    "If CH index increases but AUC plateaus, the model may be overfitting to train-specific patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Contrastive Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Calinski-Harabasz Index\n",
    "eval_epochs = list(range(1, num_epochs+1, 5))\n",
    "if 1 not in eval_epochs:\n",
    "    eval_epochs = [1] + eval_epochs\n",
    "axes[1].plot(eval_epochs[:len(history['train_separation'])], \n",
    "             history['train_separation'], marker='o', label='Train CH Index', linewidth=2)\n",
    "axes[1].plot(eval_epochs[:len(history['val_separation'])], \n",
    "             history['val_separation'], marker='o', label='Val CH Index', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Calinski-Harabasz Index')\n",
    "axes[1].set_title('Calinski-Harabasz Index (Higher is Better)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# AUC\n",
    "axes[2].plot(eval_epochs[:len(history['val_auc'])], \n",
    "             history['val_auc'], marker='o', color='green', linewidth=2)\n",
    "axes[2].axhline(y=0.5, color='red', linestyle='--', label='Random Baseline', alpha=0.5)\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Validation AUC')\n",
    "axes[2].set_title('Logistic Regression AUC on Learned Embeddings')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "axes[2].set_ylim([0.4, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Post-Training Embedding Analysis\n",
    "\n",
    "Generate the final debiased embeddings by passing all samples through the trained projection network, then compare to the original embeddings.\n",
    "\n",
    "### What to Look For:\n",
    "\n",
    "**In the is_positive plots:**\n",
    "- ✓ Clearer separation between cases (red) and controls (blue)\n",
    "- ✓ Tighter within-class clusters\n",
    "\n",
    "**In the confounder plots:**\n",
    "- ✓ Reduced correlation with confounders (more mixed colors)\n",
    "- ✓ Random scatter rather than clear gradients\n",
    "\n",
    "If confounders still show strong patterns, consider:\n",
    "- Longer training\n",
    "- Stronger weight decay\n",
    "- Explicit adversarial debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate post-training embeddings for all data\n",
    "model.eval()\n",
    "all_embeddings = torch.FloatTensor(embeddings).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Process in batches to avoid memory issues\n",
    "    batch_size_inference = 256\n",
    "    trained_embeddings_list = []\n",
    "    \n",
    "    for i in range(0, len(all_embeddings), batch_size_inference):\n",
    "        batch = all_embeddings[i:i+batch_size_inference]\n",
    "        projected = model(batch)\n",
    "        trained_embeddings_list.append(projected.cpu().numpy())\n",
    "    \n",
    "    trained_embeddings = np.vstack(trained_embeddings_list)\n",
    "\n",
    "print(f\"Generated trained embeddings: {trained_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on trained embeddings\n",
    "pca_trained = PCA(n_components=2)\n",
    "pca_coords_trained = pca_trained.fit_transform(trained_embeddings)\n",
    "\n",
    "# Add to dataframe\n",
    "df['PC1_trained'] = pca_coords_trained[:, 0]\n",
    "df['PC2_trained'] = pca_coords_trained[:, 1]\n",
    "\n",
    "print(f\"Trained embeddings - Explained variance ratio: {pca_trained.explained_variance_ratio_}\")\n",
    "print(f\"Trained embeddings - Total variance explained: {pca_trained.explained_variance_ratio_.sum():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs trained embeddings - PC1 vs PC2 colored by is_positive\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Original embeddings\n",
    "scatter1 = axes[0].scatter(df['PC1_original'], df['PC2_original'], \n",
    "                          c=df['is_positive'], cmap='coolwarm', \n",
    "                          alpha=0.6, s=20)\n",
    "axes[0].set_xlabel('PC1')\n",
    "axes[0].set_ylabel('PC2')\n",
    "axes[0].set_title('Original Embeddings (Before Training)')\n",
    "axes[0].legend(*scatter1.legend_elements(), title=\"is_positive\")\n",
    "\n",
    "# Trained embeddings\n",
    "scatter2 = axes[1].scatter(df['PC1_trained'], df['PC2_trained'], \n",
    "                          c=df['is_positive'], cmap='coolwarm', \n",
    "                          alpha=0.6, s=20)\n",
    "axes[1].set_xlabel('PC1')\n",
    "axes[1].set_ylabel('PC2')\n",
    "axes[1].set_title('Trained Embeddings (After Contrastive Learning)')\n",
    "axes[1].legend(*scatter2.legend_elements(), title=\"is_positive\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca_comparison_is_positive.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-plot comparison: Original vs Trained for each confounder\n",
    "n_confounders = len(confounder_cols) + 1  # +1 for is_positive\n",
    "n_cols = min(3, n_confounders)\n",
    "n_rows = (n_confounders + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows * 2, n_cols, figsize=(6*n_cols, 5*n_rows*2))\n",
    "axes = axes.flatten() if n_confounders > 1 else [axes]\n",
    "\n",
    "plot_idx = 0\n",
    "\n",
    "# Plot is_positive first\n",
    "for emb_type, pc1_col, pc2_col, title_suffix in [\n",
    "    ('original', 'PC1_original', 'PC2_original', 'Original'),\n",
    "    ('trained', 'PC1_trained', 'PC2_trained', 'Trained')\n",
    "]:\n",
    "    scatter = axes[plot_idx].scatter(df[pc1_col], df[pc2_col], \n",
    "                                    c=df['is_positive'], cmap='coolwarm', \n",
    "                                    alpha=0.6, s=20)\n",
    "    axes[plot_idx].set_xlabel('PC1')\n",
    "    axes[plot_idx].set_ylabel('PC2')\n",
    "    axes[plot_idx].set_title(f'PC1 vs PC2 ({title_suffix}) - is_positive')\n",
    "    axes[plot_idx].legend(*scatter.legend_elements(), title=\"is_positive\", fontsize=8)\n",
    "    plot_idx += 1\n",
    "\n",
    "# Plot each confounder\n",
    "for confounder in confounder_cols:\n",
    "    for emb_type, pc1_col, pc2_col, title_suffix in [\n",
    "        ('original', 'PC1_original', 'PC2_original', 'Original'),\n",
    "        ('trained', 'PC1_trained', 'PC2_trained', 'Trained')\n",
    "    ]:\n",
    "        if plot_idx >= len(axes):\n",
    "            break\n",
    "            \n",
    "        # Check if confounder is categorical or continuous\n",
    "        if df[confounder].dtype == 'object' or df[confounder].nunique() < 10:\n",
    "            # Categorical\n",
    "            scatter = axes[plot_idx].scatter(df[pc1_col], df[pc2_col], \n",
    "                                           c=pd.Categorical(df[confounder]).codes, \n",
    "                                           cmap='tab10', alpha=0.6, s=20)\n",
    "            axes[plot_idx].legend(*scatter.legend_elements(), title=confounder, \n",
    "                                loc='best', fontsize=8)\n",
    "        else:\n",
    "            # Continuous\n",
    "            scatter = axes[plot_idx].scatter(df[pc1_col], df[pc2_col], \n",
    "                                           c=df[confounder], cmap='viridis', \n",
    "                                           alpha=0.6, s=20)\n",
    "            plt.colorbar(scatter, ax=axes[plot_idx], label=confounder)\n",
    "        \n",
    "        axes[plot_idx].set_xlabel('PC1')\n",
    "        axes[plot_idx].set_ylabel('PC2')\n",
    "        axes[plot_idx].set_title(f'PC1 vs PC2 ({title_suffix}) - {confounder}')\n",
    "        plot_idx += 1\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(plot_idx, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca_comparison_all_confounders.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization complete! Check the saved PNG files for detailed comparisons.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Export\n",
    "\n",
    "### Final Metrics\n",
    "Quantify the improvement achieved by contrastive learning:\n",
    "- **Cluster separation improvement**: How much better are cases/controls separated?\n",
    "- **AUC improvement**: Is the embedding more useful for downstream prediction?\n",
    "\n",
    "### Saving Results\n",
    "Optionally save:\n",
    "1. **Trained embeddings**: For use in downstream analyses (GWAS, prediction models, etc.)\n",
    "2. **Model weights**: To apply the same transformation to new samples\n",
    "\n",
    "### Next Steps\n",
    "With the debiased embeddings, you can:\n",
    "- Run association studies with reduced confounding\n",
    "- Train fairer predictive models\n",
    "- Perform clustering or dimensionality reduction with less technical artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on all data\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nBest validation AUC achieved: {best_val_auc:.4f}\")\n",
    "print(f\"\\nOriginal embeddings:\")\n",
    "print(f\"  Shape: {embeddings.shape}\")\n",
    "print(f\"  PCA variance explained (PC1+PC2): {pca_original.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "print(f\"\\nTrained embeddings:\")\n",
    "print(f\"  Shape: {trained_embeddings.shape}\")\n",
    "print(f\"  PCA variance explained (PC1+PC2): {pca_trained.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "# Compute final metrics on full dataset\n",
    "final_ch_original = compute_cluster_separation(embeddings, df['is_positive'].values)\n",
    "final_ch_trained = compute_cluster_separation(trained_embeddings, df['is_positive'].values)\n",
    "\n",
    "print(f\"\\nCalinski-Harabasz Index (higher is better):\")\n",
    "print(f\"  Original embeddings: {final_ch_original:.2f}\")\n",
    "print(f\"  Trained embeddings: {final_ch_trained:.2f}\")\n",
    "print(f\"  Improvement: {((final_ch_trained - final_ch_original) / final_ch_original * 100):.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Files saved:\")\n",
    "print(\"  - pca_original_confounders.png\")\n",
    "print(\"  - training_history.png\")\n",
    "print(\"  - pca_comparison_is_positive.png\")\n",
    "print(\"  - pca_comparison_all_confounders.png\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save trained embeddings and model\n",
    "# Uncomment to save\n",
    "\n",
    "# # Save trained embeddings to parquet\n",
    "# df_export = df.copy()\n",
    "# for i in range(trained_embeddings.shape[1]):\n",
    "#     df_export[f'trained_emb_{i}'] = trained_embeddings[:, i]\n",
    "# df_export.to_parquet('embeddings_with_trained.parquet', index=False)\n",
    "# print(\"Saved embeddings with trained representations to 'embeddings_with_trained.parquet'\")\n",
    "\n",
    "# # Save model weights\n",
    "# torch.save({\n",
    "#     'model_state_dict': model.state_dict(),\n",
    "#     'input_dim': input_dim,\n",
    "#     'hidden_dim': 256,\n",
    "#     'output_dim': 128,\n",
    "#     'best_val_auc': best_val_auc\n",
    "# }, 'contrastive_model.pt')\n",
    "# print(\"Saved model weights to 'contrastive_model.pt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pre-phd-genomics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
