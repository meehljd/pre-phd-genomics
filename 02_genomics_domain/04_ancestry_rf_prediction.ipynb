{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86271e9f",
   "metadata": {},
   "source": [
    "# gnomAD v4 Ancestry Projection - Summary\n",
    "\n",
    "## Objective\n",
    "Project Tapestry samples (n=97,422) onto gnomAD v4 PC space and assign ancestry labels using the official Random Forest classifier.\n",
    "\n",
    "## Methods\n",
    "\n",
    "### 1. Data Preparation\n",
    "- Downloaded gnomAD v4 PCA loadings (Hail table format)\n",
    "- Extracted 20 PC loadings for projection\n",
    "- Identified 168,373 overlapping variants between Tapestry and gnomAD\n",
    "- Filtered monomorphic variants (AF=0 or AF=1) to enable variance standardization\n",
    "\n",
    "### 2. PC Projection\n",
    "```bash\n",
    "plink2 --score with variance-standardize modifier\n",
    "```\n",
    "- Used `--score` to compute: projected_PCs = genotypes @ gnomAD_loadings\n",
    "- Applied variance standardization (matches gnomAD's HWE-normalized PCA)\n",
    "- Multiplied SCORE_AVG × ALLELE_CT to get proper PC scale\n",
    "\n",
    "### 3. Random Forest Classification\n",
    "- Loaded gnomAD v4 RF model (ONNX format, avoids pickle version conflicts)\n",
    "- Applied to first 20 projected PCs\n",
    "- Obtained ancestry predictions + confidence scores\n",
    "\n",
    "## Results\n",
    "\n",
    "### Ancestry Distribution\n",
    "- **EUR (NFE+FIN)**: 89,639 samples (92.0%)\n",
    "  - NFE: 67,856 (69.7%)\n",
    "  - FIN: 21,783 (22.4%)\n",
    "- **Other ancestries**: ~7,783 samples (8.0%)\n",
    "\n",
    "### Critical Finding: FIN Classification Failure\n",
    "**Problem**: 22.4% classified as Finnish — **demographically implausible** for Minnesota (expected ~5-10%).\n",
    "\n",
    "**Evidence of poor separation**:\n",
    "- **Median FIN confidence: 0.32** (essentially random)\n",
    "- **80% borderline** (17,515/21,783 with prob < 0.5)\n",
    "- **Only 266 confident FIN** (prob > 0.7) = **0.3%** (more realistic)\n",
    "- **Most samples**: ~0.3 NFE prob + ~0.3 FIN prob (RF can't decide)\n",
    "\n",
    "**Visual inspection (PC11 vs PC5)**:\n",
    "- No discrete FIN/NFE clusters\n",
    "- Continuous gradient rather than separated populations\n",
    "- Suggests projection shrinkage or cohort-specific structure\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "The gnomAD RF was trained on discrete reference populations but fails on this cohort because:\n",
    "1. **Low variant overlap** → PC projection shrinkage toward 0\n",
    "2. **Continuous European variation** in Tapestry (no distinct Finnish subpopulation)\n",
    "3. **gnomAD's FIN/NFE boundary** doesn't generalize to all cohorts\n",
    "\n",
    "This is a **known limitation** mentioned in gnomAD documentation: *\"RF may not perform adequately on all datasets\"*\n",
    "\n",
    "## Decision: Collapse FIN + NFE → EUR\n",
    "\n",
    "**Rationale**:\n",
    "- 22.4% FIN is not credible for Minnesota demographics\n",
    "- Median confidence (0.32) indicates unreliable boundary\n",
    "- FIN and NFE are genetically very close (both North European)\n",
    "- Fairness analysis doesn't require sub-European resolution\n",
    "\n",
    "**Final ancestry scheme**:\n",
    "- **EUR**: Merged NFE + FIN (high confidence threshold not practical here)\n",
    "- **AFR, EAS, SAS, AMR**: Keep separate (better separated in PC space)\n",
    "```python\n",
    "# Collapse European ancestries\n",
    "pcs_clean['ancestry_final'] = pcs_clean['ancestry_rf'].replace({\n",
    "    'nfe': 'eur',\n",
    "    'fin': 'eur'\n",
    "})\n",
    "```\n",
    "\n",
    "## Files Generated\n",
    "- `tapestry_projected_pcs.csv` - 97,422 samples × 20 PCs\n",
    "- `ancestry_labels.txt` - Sample IDs + ancestry + confidence scores\n",
    "- `gnomad_projection.png` - PC visualization\n",
    "- `fin_nfe_separation_check.png` - Diagnostic plots\n",
    "\n",
    "## Next Steps (Week 3 Task 2)\n",
    "1. Use **continuous PC-based stratification** (PC deciles) for debiasing\n",
    "2. Implement **ancestry subspace removal** (project out PC1-10)\n",
    "3. Validate fairness metrics stratified by final ancestry labels\n",
    "\n",
    "## Key Takeaway\n",
    "**Discrete ancestry labels from gnomAD RF are unreliable for this cohort.** For fairness analysis, prefer:\n",
    "- Continuous PC-based debiasing (original Week 2 plan)\n",
    "- Collapsed EUR category (avoids spurious FIN/NFE split)\n",
    "- High-confidence non-EUR ancestries for stratification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac621132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Load ONNX model\n",
    "model_path = '/home/ext_meehl_joshua_mayo_edu/pre-phd-genomics/02_genomics_domain/data/gnomAD/gnomad.v4.0.RF_fit.onnx'\n",
    "session = ort.InferenceSession(model_path)\n",
    "\n",
    "# Inspect model inputs/outputs\n",
    "print(\"Model inputs:\")\n",
    "for inp in session.get_inputs():\n",
    "    print(f\"  Name: {inp.name}, Shape: {inp.shape}, Type: {inp.type}\")\n",
    "\n",
    "print(\"\\nModel outputs:\")\n",
    "for out in session.get_outputs():\n",
    "    print(f\"  Name: {out.name}, Shape: {out.shape}, Type: {out.type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14baf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pcs_clean = pd.read_csv('/home/ext_meehl_joshua_mayo_edu/pre-phd-genomics/02_genomics_domain/data/gnomAD/tapestry_projected_pcs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e826aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input (likely needs first N PCs as float32)\n",
    "# Check what the model expects from Step 1 output\n",
    "n_pcs = session.get_inputs()[0].shape[1]  # Get expected number of features\n",
    "print(f\"Model expects {n_pcs} PCs\")\n",
    "\n",
    "# Prepare features\n",
    "X = pcs_clean[[f'PC{i}' for i in range(1, n_pcs + 1)]].values.astype(np.float32)\n",
    "\n",
    "# Run inference\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_names = [out.name for out in session.get_outputs()]\n",
    "\n",
    "results = session.run(output_names, {input_name: X})\n",
    "\n",
    "# results typically contains: [labels, probabilities]\n",
    "predictions = results[0]  # Ancestry predictions\n",
    "probabilities = results[1] if len(results) > 1 else None  # Confidence scores\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "if probabilities is not None:\n",
    "    print(f\"Probabilities shape: {len(probabilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff94458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check exact input specifications\n",
    "print(\"Model input details:\")\n",
    "for inp in session.get_inputs():\n",
    "    print(f\"  Name: {inp.name}\")\n",
    "    print(f\"  Shape: {inp.shape}\")\n",
    "    print(f\"  Type: {inp.type}\")\n",
    "\n",
    "# Check your input shape\n",
    "print(f\"\\nYour input shape: {X.shape}\")\n",
    "print(f\"Your input dtype: {X.dtype}\")\n",
    "\n",
    "# Verify your input actually has variation\n",
    "print(f\"\\nFirst 5 samples, first 5 PCs:\")\n",
    "print(X[:5, :5])\n",
    "\n",
    "print(f\"\\nPC1 statistics:\")\n",
    "print(f\"  Min: {X[:, 0].min()}\")\n",
    "print(f\"  Max: {X[:, 0].max()}\")\n",
    "print(f\"  Mean: {X[:, 0].mean()}\")\n",
    "print(f\"  Std: {X[:, 0].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0a0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs_clean['ancestry_rf'] = predictions\n",
    "pcs_clean['ancestry_prob'] = [max(prob_dict.values()) for prob_dict in probabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442da6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs_clean['ancestry_rf'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e59cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs_clean['ancestry_prob'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b6836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "n_pc_search = 20\n",
    "# Get all PC columns (first 20)\n",
    "pc_cols = [f'PC{i}' for i in range(1, 21)]\n",
    "\n",
    "# Function to compute between-group variance / within-group variance\n",
    "def separation_score(data, labels, pc1, pc2):\n",
    "    \"\"\"Compute F-statistic for 2D separation\"\"\"\n",
    "    X = data[[pc1, pc2]].values\n",
    "    \n",
    "    # Between-group variance\n",
    "    group_means = []\n",
    "    for ancestry in labels.unique():\n",
    "        group_means.append(X[labels == ancestry].mean(axis=0))\n",
    "    group_means = np.array(group_means)\n",
    "    overall_mean = X.mean(axis=0)\n",
    "    between_var = np.sum([len(X[labels == anc]) * np.sum((gm - overall_mean)**2) \n",
    "                          for anc, gm in zip(labels.unique(), group_means)])\n",
    "    \n",
    "    # Within-group variance\n",
    "    within_var = np.sum([np.sum((X[labels == anc] - gm)**2) \n",
    "                         for anc, gm in zip(labels.unique(), group_means)])\n",
    "    \n",
    "    # F-statistic (higher = better separation)\n",
    "    return between_var / (within_var + 1e-10)\n",
    "\n",
    "# Test all PC pairs\n",
    "print(\"Computing separation scores for all PC pairs...\")\n",
    "scores = {}\n",
    "for pc1, pc2 in combinations(pc_cols[:n_pc_search], 2):  # Test first 10 PCs\n",
    "    score = separation_score(pcs_clean, pcs_clean['ancestry_rf'], pc1, pc2)\n",
    "    scores[(pc1, pc2)] = score\n",
    "\n",
    "# Sort by score\n",
    "sorted_pairs = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Show top 10\n",
    "print(\"\\nTop 10 PC pairs for ancestry separation:\")\n",
    "for (pc1, pc2), score in sorted_pairs[:n_pc_search]:\n",
    "    print(f\"  {pc1} vs {pc2}: {score:.2f}\")\n",
    "\n",
    "# Visualize best pair\n",
    "best_pc1, best_pc2 = sorted_pairs[0][0]\n",
    "print(f\"\\nBest pair: {best_pc1} vs {best_pc2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b6cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e3b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Number of PC pairs to plot (e.g., 10 pairs = PC1-PC20)\n",
    "n_pairs = 10\n",
    "\n",
    "# Calculate grid size (e.g., 5x2 for 10 pairs, 3x3 for 9 pairs)\n",
    "n_cols = 3\n",
    "n_rows = (n_pairs + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 6*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Get unique ancestries and colors\n",
    "ancestries = pcs_clean['ancestry_rf'].unique()\n",
    "ancestries = ['nfe', 'afr', 'fin', 'sas', 'ami', 'asj', 'eas', 'amr', 'mid']\n",
    "ancestries = ['nfe', 'fin']\n",
    "colors = dict(zip(ancestries, sns.color_palette('Set2', n_colors=len(ancestries))))\n",
    "\n",
    "for pair_idx in range(n_pairs):\n",
    "    ax = axes[pair_idx]\n",
    "    \n",
    "    # Get PC pair (PC1+PC2, PC3+PC4, etc.)\n",
    "    pc1 = f'PC{2*pair_idx + 1}'\n",
    "    pc2 = f'PC{2*pair_idx + 2}'\n",
    "    \n",
    "    # Plot each ancestry\n",
    "    for ancestry in ancestries:\n",
    "        subset = pcs_clean[pcs_clean['ancestry_rf'] == ancestry]\n",
    "        ax.scatter(subset[pc1], subset[pc2], \n",
    "                   label=ancestry if pair_idx == 0 else '',  # Legend only on first plot\n",
    "                   alpha=0.4, s=5, color=colors[ancestry])\n",
    "    \n",
    "    ax.set_xlabel(pc1, fontsize=10)\n",
    "    ax.set_ylabel(pc2, fontsize=10)\n",
    "    ax.set_title(f'{pc1} vs {pc2}', fontsize=11)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "# Add legend to first subplot\n",
    "axes[0].legend(markerscale=3, loc='best', fontsize=8)\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(n_pairs, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Consecutive PC Pairs - Ancestry Structure', fontsize=16, y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('consecutive_pc_pairs_ancestry.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d408eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pc = 'PC11'\n",
    "y_pc = 'PC5'\n",
    "\n",
    "# Look at samples with low confidence or near Finnish boundary\n",
    "pcs_clean['is_european'] = pcs_clean['ancestry_rf'].isin(['nfe', 'fin'])\n",
    "european_samples = pcs_clean[pcs_clean['is_european']]\n",
    "\n",
    "# Check FIN assignments with low confidence\n",
    "fin_samples = european_samples[european_samples['ancestry_rf'] == 'fin']\n",
    "# print(f\"\\nFinnish classifications:\")\n",
    "# print(fin_samples['ancestry_prob'].describe())\n",
    "\n",
    "# Low-confidence FIN might be admixed\n",
    "ambiguous_fin = fin_samples[fin_samples['ancestry_prob'] < 0.6]\n",
    "print(f\"\\nAmbiguous FIN: {len(ambiguous_fin)} samples\")\n",
    "\n",
    "# Plot NFE vs FIN in PC space\n",
    "import matplotlib.pyplot as plt\n",
    "nfe = european_samples[european_samples['ancestry_rf'] == 'nfe']\n",
    "fin = european_samples[european_samples['ancestry_rf'] == 'fin']\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(nfe[x_pc], nfe[y_pc], label='NFE', alpha=0.5, s=10)\n",
    "plt.scatter(fin[x_pc], fin[y_pc], label='FIN', alpha=0.5, s=10)\n",
    "plt.xlabel(x_pc)\n",
    "plt.ylabel(y_pc)\n",
    "plt.legend()\n",
    "plt.title('NFE vs FIN classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5f8028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are these low-confidence classifications?\n",
    "fin_samples = pcs_clean[pcs_clean['ancestry_rf'] == 'fin']\n",
    "\n",
    "print(f\"FIN samples: {len(fin_samples)} ({len(fin_samples)/len(pcs_clean)*100:.1f}%)\")\n",
    "print(\"\\nFIN confidence distribution:\")\n",
    "print(fin_samples['ancestry_prob'].describe())\n",
    "\n",
    "# How many are confidently FIN (>0.7)?\n",
    "confident_fin = fin_samples[fin_samples['ancestry_prob'] > 0.7]\n",
    "print(f\"\\nConfident FIN (prob > 0.7): {len(confident_fin)} ({len(confident_fin)/len(pcs_clean)*100:.1f}%)\")\n",
    "\n",
    "# How many are borderline?\n",
    "borderline_fin = fin_samples[fin_samples['ancestry_prob'] < 0.5]\n",
    "print(f\"Borderline FIN (prob < 0.5): {len(borderline_fin)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d0c884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pre-phd-genomics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
