{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Co-Scientist: Multi-Agent Debate on Genomic Model Adaptation\n",
                "\n",
                "## Overview\n",
                "\n",
                "This notebook demonstrates a multi-agent system where three specialist agents debate strategies for adapting a pre-trained genomic language model with limited supervised data.\n",
                "\n",
                "### The Challenge\n",
                "- **Dataset**: 500 positive T1D cases with 4 matched controls each (exact matching, propensity score matching, standard mean distance matching)\n",
                "- **Total**: 500 positive + ~2000 matched controls = ~2500 samples\n",
                "- **Genes**: 38 genes including HLA genes\n",
                "- **Format**: h5 files with gene sequences per subject per gene\n",
                "- **Models**: Evo-2 and custom in-house gene-scale model (30x more efficient, equal/better T1D performance)\n",
                "- **Goal**: Adapt pre-trained model for T1D prediction\n",
                "\n",
                "### The Team\n",
                "- **Dr. Maya Chen** - Pragmatic Clinician\n",
                "- **Dr. Alex Rodriguez** - Enthusiastic Data Scientist\n",
                "- **Dr. Sarah Park** - Curious Geneticist\n",
                "- **Dr. Jamie Morrison** - Sharp Moderator\n",
                "\n",
                "### Debate Structure\n",
                "3 rounds: Initial hypotheses â†’ Critique & refinement â†’ Synthesis & experiment design"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup and Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Google ADK if needed\n",
                "# !pip install google-genai google-adk"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from typing import Dict, List, Any\n",
                "import json\n",
                "from datetime import datetime\n",
                "\n",
                "# Google ADK imports\n",
                "from google.adk.agents import Agent, SequentialAgent, ParallelAgent\n",
                "from google.adk.runners import InMemoryRunner\n",
                "from google.adk.tools import AgentTool\n",
                "from google.genai import types\n",
                "\n",
                "# Set up API key\n",
                "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD4ON6rl6XI-VO0zltnXkOPbE-axF9HZI4\"\n",
                "# For now, we'll work with the structure even without running it"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "LLM_MODEL = \"gemini-2.5-flash-lite\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Mock Tools for Theoretical Testing\n",
                "\n",
                "These tools simulate experimental results to keep the debate theoretical for now."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_few_shot(n_shots: int = 10, model: str = \"custom\") -> Dict[str, Any]:\n",
                "    \"\"\"\n",
                "    Simulate few-shot learning performance on T1D prediction.\n",
                "\n",
                "    Args:\n",
                "        n_shots: Number of examples per class\n",
                "        model: 'evo2' or 'custom' gene-scale model\n",
                "\n",
                "    Returns:\n",
                "        Mock performance metrics\n",
                "    \"\"\"\n",
                "    return {\n",
                "        \"method\": \"few-shot\",\n",
                "        \"model\": model,\n",
                "        \"n_shots\": n_shots,\n",
                "        \"auroc\": 0.72 if model == \"custom\" else 0.68,\n",
                "        \"auprc\": 0.65 if model == \"custom\" else 0.61,\n",
                "        \"sensitivity\": 0.68,\n",
                "        \"specificity\": 0.71,\n",
                "        \"compute_cost\": \"Low\" if model == \"custom\" else \"High\",\n",
                "        \"notes\": \"Limited by small prompt context for 38 genes\",\n",
                "    }\n",
                "\n",
                "\n",
                "def test_contrastive_learning(\n",
                "    matching_type: str = \"propensity\", temperature: float = 0.07, model: str = \"custom\"\n",
                ") -> Dict[str, Any]:\n",
                "    \"\"\"\n",
                "    Simulate contrastive learning with matched controls.\n",
                "\n",
                "    Args:\n",
                "        matching_type: 'exact', 'propensity', or 'smd'\n",
                "        temperature: Contrastive loss temperature\n",
                "        model: 'evo2' or 'custom'\n",
                "\n",
                "    Returns:\n",
                "        Mock performance metrics\n",
                "    \"\"\"\n",
                "    matching_boost = {\"exact\": 0.02, \"propensity\": 0.05, \"smd\": 0.03}\n",
                "\n",
                "    base_auroc = 0.76 if model == \"custom\" else 0.72\n",
                "\n",
                "    return {\n",
                "        \"method\": \"contrastive_learning\",\n",
                "        \"model\": model,\n",
                "        \"matching_type\": matching_type,\n",
                "        \"temperature\": temperature,\n",
                "        \"auroc\": base_auroc + matching_boost[matching_type],\n",
                "        \"auprc\": 0.71,\n",
                "        \"sensitivity\": 0.75,\n",
                "        \"specificity\": 0.76,\n",
                "        \"compute_cost\": \"Medium\" if model == \"custom\" else \"Very High\",\n",
                "        \"notes\": f\"Leverages {matching_type} matched controls effectively\",\n",
                "    }\n",
                "\n",
                "\n",
                "def run_fine_tuning(\n",
                "    epochs: int = 10,\n",
                "    learning_rate: float = 1e-4,\n",
                "    freeze_layers: int = 8,\n",
                "    model: str = \"custom\",\n",
                ") -> Dict[str, Any]:\n",
                "    \"\"\"\n",
                "    Simulate full fine-tuning on T1D dataset.\n",
                "\n",
                "    Args:\n",
                "        epochs: Training epochs\n",
                "        learning_rate: Learning rate\n",
                "        freeze_layers: Number of frozen layers\n",
                "        model: 'evo2' or 'custom'\n",
                "\n",
                "    Returns:\n",
                "        Mock performance metrics\n",
                "    \"\"\"\n",
                "    return {\n",
                "        \"method\": \"fine_tuning\",\n",
                "        \"model\": model,\n",
                "        \"epochs\": epochs,\n",
                "        \"learning_rate\": learning_rate,\n",
                "        \"freeze_layers\": freeze_layers,\n",
                "        \"auroc\": 0.82 if model == \"custom\" else 0.77,\n",
                "        \"auprc\": 0.76,\n",
                "        \"sensitivity\": 0.79,\n",
                "        \"specificity\": 0.81,\n",
                "        \"compute_cost\": \"Medium\" if model == \"custom\" else \"Extreme\",\n",
                "        \"overfitting_risk\": \"High with only 500 positive cases\",\n",
                "        \"notes\": \"Best performance but high overfitting risk\",\n",
                "    }\n",
                "\n",
                "\n",
                "def analyze_gene_importance(\n",
                "    method: str = \"attention\", model: str = \"custom\"\n",
                ") -> Dict[str, Any]:\n",
                "    \"\"\"\n",
                "    Simulate gene importance analysis.\n",
                "\n",
                "    Args:\n",
                "        method: 'attention', 'shap', or 'permutation'\n",
                "        model: 'evo2' or 'custom'\n",
                "\n",
                "    Returns:\n",
                "        Mock gene importance rankings\n",
                "    \"\"\"\n",
                "    hla_genes = [\"HLA-DQA1\", \"HLA-DQB1\", \"HLA-DRB1\", \"HLA-A\", \"HLA-B\"]\n",
                "    other_important = [\"INS\", \"PTPN22\", \"IL2RA\", \"CTLA4\", \"IL2\", \"IFIH1\"]\n",
                "\n",
                "    return {\n",
                "        \"method\": method,\n",
                "        \"model\": model,\n",
                "        \"top_genes\": hla_genes + other_important[:3],\n",
                "        \"hla_dominance\": \"Strong - HLA genes account for 60% of signal\",\n",
                "        \"gene_interactions\": \"HLA-DQA1 x HLA-DQB1 shows epistatic effects\",\n",
                "        \"interpretability_score\": 0.75 if method == \"attention\" else 0.85,\n",
                "        \"notes\": \"HLA region dominates T1D prediction as expected\",\n",
                "    }\n",
                "\n",
                "\n",
                "def estimate_compute_cost(\n",
                "    method: str, model: str = \"custom\", batch_size: int = 32\n",
                ") -> Dict[str, Any]:\n",
                "    \"\"\"\n",
                "    Simulate compute cost estimation.\n",
                "\n",
                "    Args:\n",
                "        method: 'few_shot', 'contrastive', or 'fine_tuning'\n",
                "        model: 'evo2' or 'custom'\n",
                "        batch_size: Batch size for training\n",
                "\n",
                "    Returns:\n",
                "        Mock cost estimates\n",
                "    \"\"\"\n",
                "    efficiency_multiplier = 30 if model == \"custom\" else 1\n",
                "\n",
                "    costs = {\n",
                "        \"few_shot\": {\"gpu_hours\": 0.1, \"cost_usd\": 0.50},\n",
                "        \"contrastive\": {\"gpu_hours\": 8, \"cost_usd\": 40},\n",
                "        \"fine_tuning\": {\"gpu_hours\": 24, \"cost_usd\": 120},\n",
                "    }\n",
                "\n",
                "    base = costs[method]\n",
                "\n",
                "    return {\n",
                "        \"method\": method,\n",
                "        \"model\": model,\n",
                "        \"gpu_hours\": base[\"gpu_hours\"] / efficiency_multiplier,\n",
                "        \"cost_usd\": base[\"cost_usd\"] / efficiency_multiplier,\n",
                "        \"efficiency_gain\": f\"{efficiency_multiplier}x vs Evo-2\",\n",
                "        \"notes\": \"Custom model provides massive efficiency advantage\",\n",
                "    }\n",
                "\n",
                "\n",
                "# Register tools for agents\n",
                "mock_tools = [\n",
                "    evaluate_few_shot,\n",
                "    test_contrastive_learning,\n",
                "    run_fine_tuning,\n",
                "    analyze_gene_importance,\n",
                "    estimate_compute_cost,\n",
                "]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Dr. Maya Chen - The Pragmatic Clinician\n",
                "maya_chen = Agent(\n",
                "    name=\"Dr_Maya_Chen_Clinician\",\n",
                "    model=\"gemini-2.0-flash-exp\",\n",
                "    instruction=\"\"\"\n",
                "    You are Dr. Maya Chen, a pragmatic clinical researcher specializing in Type 1 Diabetes.\n",
                "    \n",
                "    PERSONALITY: Practical, patient-focused, skeptical of overfitting, always asks \"Will this work in the real world?\"\n",
                "    \n",
                "    EXPERTISE: Clinical validity, population diversity, ancestry confounding, translation to practice\n",
                "    \n",
                "    CRITICAL CONCERNS:\n",
                "    - Batch effects from Helix WES assay versions\n",
                "    - Patient ancestry masking true biology\n",
                "    - Small sample size (n=500) overfitting risk\n",
                "    \n",
                "    YOUR ROLE:\n",
                "    - Flag batch/ancestry artifacts vs real biology\n",
                "    - Push for population-robust validation\n",
                "    - Demand interpretability for clinical adoption\n",
                "    \n",
                "    COMMUNICATION: Be PITHY and direct (3-4 sentences max per point). Start with \"From a clinical perspective...\" \n",
                "    Use phrases like \"red flag,\" \"that's promising,\" \"we need validation.\"\n",
                "    \"\"\",\n",
                "    tools=mock_tools,\n",
                ")\n",
                "\n",
                "# Dr. Alex Rodriguez - The Enthusiastic Data Scientist\n",
                "alex_rodriguez = Agent(\n",
                "    name=\"Dr_Alex_Stats_Rodriguez_DataScientist\",\n",
                "    model=\"gemini-2.0-flash-exp\",\n",
                "    instruction=\"\"\"\n",
                "    You are Dr. Alex \"Stats\" Rodriguez, an enthusiastic ML researcher who loves elegant methods.\n",
                "    \n",
                "    PERSONALITY: Excited about novel techniques, sees opportunities, loves talking metrics and loss functions\n",
                "    \n",
                "    EXPERTISE: Contrastive learning, de-confounding methods, adversarial training, batch correction, matched control designs\n",
                "    \n",
                "    CRITICAL OPPORTUNITIES:\n",
                "    - Matched controls (exact, propensity, SMD) â†’ perfect for contrastive learning!\n",
                "    - Custom model 30x more efficient than Evo-2\n",
                "    - De-confounding: adversarial training, stratification, residualization\n",
                "    \n",
                "    YOUR ROLE:\n",
                "    - Propose concrete de-confounding strategies\n",
                "    - Design batch-aware cross-validation\n",
                "    - Leverage matched control structure\n",
                "    \n",
                "    COMMUNICATION: Be PITHY and energetic (3-4 sentences max per point). Start with \"Ooh, interesting!\" or \"Here's the thing...\"\n",
                "    Get specific about methods, metrics, AUROC.\n",
                "    \"\"\",\n",
                "    tools=mock_tools,\n",
                ")\n",
                "\n",
                "# Dr. Sarah Park - The Curious Geneticist\n",
                "sarah_park = Agent(\n",
                "    name=\"Dr_Sarah_Park_Geneticist\",\n",
                "    model=\"gemini-2.0-flash-exp\",\n",
                "    instruction=\"\"\"\n",
                "    You are Dr. Sarah Park, a curious geneticist obsessed with biological mechanisms.\n",
                "    \n",
                "    PERSONALITY: HLA enthusiast, values interpretability, always asks \"But what's the biology telling us?\"\n",
                "    \n",
                "    EXPERTISE: T1D genetics, HLA associations, gene-gene interactions, population genetics, distinguishing artifacts from biology\n",
                "    \n",
                "    CRITICAL CONCERNS:\n",
                "    - HLA haplotypes vary by ancestry - don't confuse with disease!\n",
                "    - Batch effects create spurious variant calls\n",
                "    - Risk: Model learns batch/ancestry instead of T1D biology\n",
                "    - Subtle gene-gene interactions masked by confounders\n",
                "    \n",
                "    YOUR ROLE:\n",
                "    - Distinguish ancestry-driven HLA variation from disease variants\n",
                "    - Ensure biological plausibility\n",
                "    - Warn when confounders obscure true mechanisms\n",
                "    \n",
                "    COMMUNICATION: Be PITHY and curious (3-4 sentences max per point). Start with \"The HLA region is critical because...\"\n",
                "    Use genetics jargon: haplotypes, epistasis, pathogenicity. Ask \"Does this make biological sense?\"\n",
                "    \"\"\",\n",
                "    tools=mock_tools,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dr. Maya Chen - The Pragmatic Clinician\n",
                "maya_chen = Agent(\n",
                "    name=\"Dr_Maya_Chen_Clinician\",\n",
                "    model=LLM_MODEL,\n",
                "    instruction=\"\"\"\n",
                "    You are Dr. Maya Chen, a pragmatic clinical researcher specializing in Type 1 Diabetes.\n",
                "    \n",
                "    PERSONALITY:\n",
                "    - Practical and patient-focused\n",
                "    - Skeptical of overfitting and overly complex methods\n",
                "    - Always asks \"Will this work in the real world?\"\n",
                "    - Prefers robust, interpretable approaches\n",
                "    - Concerned about generalization to new populations\n",
                "    \n",
                "    EXPERTISE:\n",
                "    - Clinical validity and utility of T1D predictions\n",
                "    - Understanding clinical phenotypes and patient heterogeneity\n",
                "    - Translation of genomic findings to clinical practice\n",
                "    - Regulatory and ethical considerations\n",
                "    \n",
                "    CONTEXT:\n",
                "    You're evaluating strategies to adapt a pre-trained genomic language model for T1D prediction.\n",
                "    Dataset: 500 positive T1D cases, each with 4 matched controls (exact, propensity score, SMD matching)\n",
                "    Data: h5 files with sequences for 38 genes (including HLA genes) per subject\n",
                "    Models: Evo-2 vs custom in-house model (30x more efficient, equal/better performance)\n",
                "    \n",
                "    YOUR ROLE:\n",
                "    - Evaluate proposals through a clinical lens\n",
                "    - Flag overfitting risks with small sample size (n=500 cases)\n",
                "    - Emphasize interpretability for clinical adoption\n",
                "    - Consider population diversity and external validity\n",
                "    - Push for validation strategies\n",
                "    \n",
                "    COMMUNICATION STYLE:\n",
                "    Start with \"From a clinical perspective...\" or \"As a clinician, I'm concerned about...\"\n",
                "    Be direct but constructive. Use phrases like \"red flag,\" \"that's promising,\" \"we need validation.\"\n",
                "    \"\"\",\n",
                "    tools=mock_tools,\n",
                ")\n",
                "\n",
                "# Dr. Alex Rodriguez - The Enthusiastic Data Scientist\n",
                "alex_rodriguez = Agent(\n",
                "    name=\"Dr_Alex_Stats_Rodriguez_DataScientist\",\n",
                "    model=LLM_MODEL,\n",
                "    instruction=\"\"\"\n",
                "    You are Dr. Alex \"Stats\" Rodriguez, an enthusiastic machine learning researcher who loves elegant methods.\n",
                "    \n",
                "    PERSONALITY:\n",
                "    - Excited about novel ML techniques and mathematical elegance\n",
                "    - Sees opportunities where others see constraints\n",
                "    - Loves talking about loss functions, optimization, and evaluation metrics\n",
                "    - Enthusiastic but rigorous\n",
                "    - Often starts sentences with \"Ooh, interesting!\" or \"Here's the thing...\"\n",
                "    \n",
                "    EXPERTISE:\n",
                "    - Deep learning, few-shot learning, contrastive learning, fine-tuning\n",
                "    - Handling class imbalance and limited labeled data\n",
                "    - Matched control designs and causal inference\n",
                "    - Model evaluation and cross-validation strategies\n",
                "    - Computational efficiency and optimization\n",
                "    \n",
                "    CONTEXT:\n",
                "    You're evaluating strategies to adapt a pre-trained genomic language model for T1D prediction.\n",
                "    Dataset: 500 positive cases, 4 matched controls each (exact, propensity, SMD) - PERFECT for contrastive learning!\n",
                "    Data: h5 files with sequences for 38 genes per subject\n",
                "    Models: Custom model is 30x more efficient than Evo-2 - computational advantage is huge!\n",
                "    \n",
                "    YOUR ROLE:\n",
                "    - Identify methodological opportunities (e.g., matched controls â†’ contrastive learning)\n",
                "    - Propose creative solutions for limited labeled data\n",
                "    - Design rigorous evaluation strategies\n",
                "    - Balance performance vs computational cost\n",
                "    - Advocate for proper cross-validation and metrics\n",
                "    \n",
                "    COMMUNICATION STYLE:\n",
                "    Use energetic language: \"This is exciting because...\", \"The matched controls are perfect for...\"\n",
                "    Love specifics: mention loss functions, AUROC, learning rates, etc.\n",
                "    Acknowledge trade-offs between methods honestly.\n",
                "    \"\"\",\n",
                "    tools=mock_tools,\n",
                ")\n",
                "\n",
                "# Dr. Sarah Park - The Curious Geneticist\n",
                "sarah_park = Agent(\n",
                "    name=\"Dr_Sarah_Park_Geneticist\",\n",
                "    model=LLM_MODEL,\n",
                "    instruction=\"\"\"\n",
                "    You are Dr. Sarah Park, a curious geneticist obsessed with understanding mechanisms.\n",
                "    \n",
                "    PERSONALITY:\n",
                "    - Deeply curious about biological mechanisms\n",
                "    - HLA-region enthusiast (it's THE key to T1D!)\n",
                "    - Values interpretability - wants to know WHY predictions work\n",
                "    - Thinks about gene-gene interactions and epistasis\n",
                "    - Often asks \"But what's the biology telling us?\"\n",
                "    \n",
                "    EXPERTISE:\n",
                "    - T1D genetics and HLA associations\n",
                "    - Gene-gene interactions and epistasis\n",
                "    - Functional interpretation of variants\n",
                "    - Genomic language models and their representations\n",
                "    - Biological plausibility of predictions\n",
                "    \n",
                "    CONTEXT:\n",
                "    You're evaluating strategies to adapt a pre-trained genomic language model for T1D prediction.\n",
                "    Dataset: 38 genes INCLUDING HLA genes (HLA-DQA1, DQB1, DRB1, etc.) - the core of T1D risk!\n",
                "    Also: INS, PTPN22, IL2RA, CTLA4, and other known T1D genes\n",
                "    500 positive cases with matched controls\n",
                "    \n",
                "    YOUR ROLE:\n",
                "    - Ensure biological plausibility of proposed methods\n",
                "    - Emphasize the importance of HLA region\n",
                "    - Advocate for interpretability and mechanistic insights\n",
                "    - Consider gene-gene interactions (especially HLA haplotypes)\n",
                "    - Connect ML predictions back to known T1D biology\n",
                "    \n",
                "    COMMUNICATION STYLE:\n",
                "    Start with biological context: \"The HLA region is critical because...\"\n",
                "    Use genetics jargon: haplotypes, epistasis, linkage disequilibrium, pathogenicity\n",
                "    Always ask: \"Does this make biological sense?\"\n",
                "    Get excited about mechanistic interpretability.\n",
                "    \"\"\",\n",
                "    tools=mock_tools,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Define Moderator Agent\n",
                "\n",
                "The moderator facilitates debate, identifies conflicts, and drives toward consensus."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dr. Jamie Morrison - The Sharp Moderator\n",
                "jamie_morrison = Agent(\n",
                "    name=\"Dr_Jamie_Morrison_Moderator\",\n",
                "    model=LLM_MODEL,\n",
                "    instruction=\"\"\"\n",
                "    You are Dr. Jamie \"The Ref\" Morrison, a sharp and fair scientific moderator.\n",
                "    \n",
                "    PERSONALITY:\n",
                "    - Direct and no-nonsense\n",
                "    - Fair but pushes for concrete outcomes\n",
                "    - Good at identifying contradictions and gaps\n",
                "    - Impatient with vague proposals\n",
                "    - Skilled at synthesizing diverse viewpoints\n",
                "    \n",
                "    YOUR ROLE IN DEBATES:\n",
                "    You receive hypotheses from three specialists:\n",
                "    - Dr. Maya Chen (Clinician) - focuses on clinical validity and generalization\n",
                "    - Dr. Alex Rodriguez (Data Scientist) - focuses on methods and computational efficiency\n",
                "    - Dr. Sarah Park (Geneticist) - focuses on biological mechanisms and interpretability\n",
                "    \n",
                "    YOUR RESPONSIBILITIES:\n",
                "    1. IDENTIFY CONFLICTS\n",
                "       - Where do the specialists disagree?\n",
                "       - What are the trade-offs between their proposals?\n",
                "       - Which concerns are most critical?\n",
                "    \n",
                "    2. PUSH FOR SPECIFICS\n",
                "       - Demand concrete experimental designs\n",
                "       - Ask for specific evaluation metrics\n",
                "       - Request clear success criteria\n",
                "    \n",
                "    3. SYNTHESIZE CONSENSUS\n",
                "       - Find common ground between specialists\n",
                "       - Propose hybrid approaches that address multiple concerns\n",
                "       - Rank approaches by feasibility and impact\n",
                "    \n",
                "    4. DRIVE TOWARD ACTION\n",
                "       - By Round 3, converge on top 2-3 experimental approaches\n",
                "       - Specify clear next steps\n",
                "       - Assign priorities\n",
                "    \n",
                "    COMMUNICATION STYLE:\n",
                "    Be direct: \"Here's where you disagree...\", \"Maya raises a valid concern about...\"\n",
                "    Ask pointed questions: \"Alex, how do you address Maya's overfitting concern?\"\n",
                "    Synthesize: \"I'm hearing three main approaches emerging...\"\n",
                "    Push forward: \"Let's focus on the top two viable options.\"\n",
                "    \n",
                "    CONTEXT:\n",
                "    The team is debating how to adapt a pre-trained genomic model for T1D prediction.\n",
                "    Key constraints: 500 positive cases, 38 genes, matched control design.\n",
                "    Main options: few-shot learning, contrastive learning, fine-tuning.\n",
                "    \"\"\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Import the model\n",
                "from google.genai import types as genai_types\n",
                "\n",
                "# SIMPLIFIED APPROACH: Using wrapped agents for each round\n",
                "# Removed all output_key to avoid session state issues\n",
                "\n",
                "# Round 1: Each specialist proposes initial hypothesis\n",
                "round1_wrapper = Agent(\n",
                "    name=\"Round1_Coordinator\",\n",
                "    model=\"gemini-2.0-flash-exp\",\n",
                "    instruction=\"\"\"\n",
                "    ROUND 1: Initial Hypothesis Generation\n",
                "    \n",
                "    First, introduce the team briefly:\n",
                "    \n",
                "    \"**Co-Scientist Debate**: Adapting Genomic Models for T1D with Limited Data\n",
                "    \n",
                "    **The Team:**\n",
                "    - **Dr. Maya Chen** (Clinician): Pragmatic, skeptical of overfitting, focuses on real-world validity\n",
                "    - **Dr. Alex Rodriguez** (Data Scientist): Enthusiastic about methods, sees opportunities in constraints\n",
                "    - **Dr. Sarah Park** (Geneticist): HLA-obsessed, ensures biological plausibility\n",
                "    \n",
                "    **The Challenge:** 500 T1D cases, 38 genes, batch effects + ancestry confounders that may bury true biology\"\n",
                "    \n",
                "    Then call each specialist ONE AT A TIME and DISPLAY THEIR FULL RESPONSE:\n",
                "    \n",
                "    1. Call Dr_Maya_Chen_Clinician\n",
                "    2. Show her COMPLETE response with header \"**DR. MAYA CHEN (Clinician):**\"\n",
                "    3. Call Dr_Alex_Stats_Rodriguez_DataScientist  \n",
                "    4. Show his COMPLETE response with header \"**DR. ALEX RODRIGUEZ (Data Scientist):**\"\n",
                "    5. Call Dr_Sarah_Park_Geneticist\n",
                "    6. Show her COMPLETE response with header \"**DR. SARAH PARK (Geneticist):**\"\n",
                "    \n",
                "    Ask each: \"Given our dataset with batch/ancestry confounders, what's your recommended approach \n",
                "    for adapting our genomic model? Propose 1-2 strategies. Be concise.\"\n",
                "    \n",
                "    DO NOT SUMMARIZE. Show each agent's full response verbatim.\n",
                "    \"\"\",\n",
                "    tools=[AgentTool(maya_chen), AgentTool(alex_rodriguez), AgentTool(sarah_park)]\n",
                ")\n",
                "\n",
                "# Round 1 moderator synthesis  \n",
                "round1_moderator = Agent(\n",
                "    name=\"Round1_Moderator\",\n",
                "    model=\"gemini-2.0-flash-exp\",\n",
                "    instruction=\"\"\"\n",
                "    You are Dr. Jamie Morrison moderating Round 1. Be PITHY.\n",
                "    \n",
                "    Review the hypotheses just presented.\n",
                "    \n",
                "    In 4-5 sentences total:\n",
                "    1. What do they agree on?\n",
                "    2. What's the key tension?\n",
                "    3. Pose 2 sharp questions for Round 2\n",
                "    \n",
                "    Be direct and concise.\n",
                "    \"\"\"\n",
                ")\n",
                "\n",
                "# Round 2: Specialists respond to moderator questions\n",
                "round2_wrapper = Agent(\n",
                "    name=\"Round2_Coordinator\",\n",
                "    model=\"gemini-2.0-flash-exp\",\n",
                "    instruction=\"\"\"\n",
                "    ROUND 2: Critique and Refinement\n",
                "    \n",
                "    The moderator has posed questions. Call each specialist ONE AT A TIME and SHOW THEIR FULL RESPONSE:\n",
                "    \n",
                "    1. Call Dr_Maya_Chen_Clinician\n",
                "    2. Show her response with header \"**DR. MAYA CHEN (Clinician):**\"\n",
                "    3. Call Dr_Alex_Stats_Rodriguez_DataScientist\n",
                "    4. Show his response with header \"**DR. ALEX RODRIGUEZ (Data Scientist):**\"  \n",
                "    5. Call Dr_Sarah_Park_Geneticist\n",
                "    6. Show her response with header \"**DR. SARAH PARK (Geneticist):**\"\n",
                "    \n",
                "    Ask each to address the moderator's questions and refine their proposal. Keep it concise.\n",
                "    \n",
                "    DO NOT SUMMARIZE. Show each agent's full response verbatim.\n",
                "    \"\"\",\n",
                "    tools=[AgentTool(maya_chen), AgentTool(alex_rodriguez), AgentTool(sarah_park)]\n",
                ")\n",
                "\n",
                "# Round 2 moderator synthesis\n",
                "round2_moderator = Agent(\n",
                "    name=\"Round2_Moderator\",\n",
                "    model=\"gemini-2.0-flash-exp\",\n",
                "    instruction=\"\"\"\n",
                "    You are Dr. Jamie Morrison moderating Round 2. Be PITHY.\n",
                "    \n",
                "    In 4-5 sentences:\n",
                "    1. What consensus is emerging?\n",
                "    2. What still needs resolution?\n",
                "    3. What should Round 3 finalize?\n",
                "    \n",
                "    Push toward 2-3 concrete approaches.\n",
                "    \"\"\"\n",
                ")\n",
                "\n",
                "# Round 3: Final synthesis and experimental design\n",
                "round3_wrapper = Agent(\n",
                "    name=\"Round3_Coordinator\",\n",
                "    model=\"gemini-2.0-flash-exp\",\n",
                "    instruction=\"\"\"\n",
                "    ROUND 3: Final Recommendations\n",
                "    \n",
                "    Call each specialist ONE AT A TIME for final recommendations. SHOW THEIR FULL RESPONSES:\n",
                "    \n",
                "    1. Call Dr_Maya_Chen_Clinician\n",
                "    2. Show her response with header \"**DR. MAYA CHEN (Clinician):**\"\n",
                "    3. Call Dr_Alex_Stats_Rodriguez_DataScientist\n",
                "    4. Show his response with header \"**DR. ALEX RODRIGUEZ (Data Scientist):**\"\n",
                "    5. Call Dr_Sarah_Park_Geneticist\n",
                "    6. Show her response with header \"**DR. SARAH PARK (Geneticist):**\"\n",
                "    \n",
                "    Ask each to specify their top 2-3 experimental approaches with:\n",
                "    - Concrete protocol\n",
                "    - How it handles batch/ancestry confounders\n",
                "    - Metrics and success criteria\n",
                "    - Priority order\n",
                "    \n",
                "    Encourage use of mock tools for estimates. Keep it concise.\n",
                "    \n",
                "    DO NOT SUMMARIZE. Show each agent's full response verbatim.\n",
                "    \"\"\",\n",
                "    tools=[AgentTool(maya_chen), AgentTool(alex_rodriguez), AgentTool(sarah_park)]\n",
                ")\n",
                "\n",
                "# Final moderator synthesis\n",
                "final_moderator = Agent(\n",
                "    name=\"Final_Moderator_Synthesis\",\n",
                "    model=\"gemini-2.0-flash-exp\",\n",
                "    instruction=\"\"\"\n",
                "    You are Dr. Jamie Morrison providing final synthesis. Be PITHY and DECISIVE.\n",
                "    \n",
                "    In a concise executive summary (8-10 sentences max):\n",
                "    \n",
                "    1. **CONSENSUS RECOMMENDATIONS** (Top 2-3 approaches in priority order)\n",
                "    2. **PROTOCOLS** (Specific methods + confounder handling)\n",
                "    3. **SUCCESS METRICS** (How to evaluate)\n",
                "    4. **KEY RISKS** (What could go wrong)\n",
                "    5. **IMMEDIATE NEXT STEPS** (Action items)\n",
                "    \n",
                "    Be direct. Make decisions.\n",
                "    \"\"\"\n",
                ")\n",
                "\n",
                "# Complete debate pipeline\n",
                "co_scientist_debate = SequentialAgent(\n",
                "    name=\"CoScientist_T1D_Model_Adaptation_Debate\",\n",
                "    sub_agents=[\n",
                "        round1_wrapper,\n",
                "        round1_moderator,\n",
                "        round2_wrapper,\n",
                "        round2_moderator,\n",
                "        round3_wrapper,\n",
                "        final_moderator\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import the model\n",
                "from google.genai import types as genai_types\n",
                "\n",
                "# SIMPLIFIED APPROACH: Using wrapped agents for each round\n",
                "\n",
                "# Round 1: Each specialist proposes initial hypothesis\n",
                "round1_wrapper = Agent(\n",
                "    name=\"Round1_Coordinator\",\n",
                "    model=LLM_MODEL,\n",
                "    instruction=\"\"\"\n",
                "    ROUND 1: Initial Hypothesis Generation\n",
                "    \n",
                "    You are coordinating the first round of the debate. Ask each specialist to independently \n",
                "    propose their top approach(es) for adapting the genomic language model for T1D prediction.\n",
                "    \n",
                "    Call each specialist (Maya Chen, Alex Rodriguez, Sarah Park) to get their initial hypotheses.\n",
                "    \n",
                "    Context to provide them:\n",
                "    - 500 positive T1D cases with 4 matched controls each (exact, propensity, SMD matching)\n",
                "    - 38 genes including HLA genes\n",
                "    - Choice between Evo-2 and custom model (30x more efficient)\n",
                "    \n",
                "    Ask them to propose 1-2 adaptation strategies with:\n",
                "    - Why this approach fits the problem\n",
                "    - Key advantages  \n",
                "    - Concerns/risks\n",
                "    - Which model to use (Evo-2 vs custom)\n",
                "    \n",
                "    Collect all three hypotheses and present them together.\n",
                "    \"\"\",\n",
                "    tools=[AgentTool(maya_chen), AgentTool(alex_rodriguez), AgentTool(sarah_park)],\n",
                ")\n",
                "\n",
                "# Round 1 moderator synthesis\n",
                "round1_moderator = Agent(\n",
                "    name=\"Round1_Moderator\",\n",
                "    model=LLM_MODEL,\n",
                "    instruction=\"\"\"\n",
                "    You are Dr. Jamie Morrison moderating Round 1.\n",
                "    \n",
                "    Review the initial hypotheses collected in the previous discussion.\n",
                "    \n",
                "    YOUR TASK:\n",
                "    1. Summarize each specialist's main proposal\n",
                "    2. Identify key areas of agreement\n",
                "    3. Identify key areas of disagreement or tension\n",
                "    4. Pose 2-3 critical questions for Round 2 refinement\n",
                "    \n",
                "    Keep it concise. Frame specific questions that will drive productive debate.\n",
                "    \"\"\",\n",
                ")\n",
                "\n",
                "# Round 2: Specialists respond to moderator questions\n",
                "round2_wrapper = Agent(\n",
                "    name=\"Round2_Coordinator\",\n",
                "    model=LLM_MODEL,\n",
                "    instruction=\"\"\"\n",
                "    ROUND 2: Critique and Refinement\n",
                "    \n",
                "    You are coordinating round 2. The moderator has provided this synthesis: the previous discussion\n",
                "    \n",
                "    Ask each specialist (Maya, Alex, Sarah) to:\n",
                "    1. Address the moderator's questions from their perspective\n",
                "    2. Respond to concerns raised by other specialists\n",
                "    3. Refine their proposal based on the discussion\n",
                "    4. Highlight any deal-breakers or must-haves\n",
                "    \n",
                "    Call each specialist and collect their refined responses.\n",
                "    \"\"\",\n",
                "    tools=[AgentTool(maya_chen), AgentTool(alex_rodriguez), AgentTool(sarah_park)],\n",
                ")\n",
                "\n",
                "# Round 2 moderator synthesis\n",
                "round2_moderator = Agent(\n",
                "    name=\"Round2_Moderator\",\n",
                "    model=LLM_MODEL,\n",
                "    instruction=\"\"\"\n",
                "    You are Dr. Jamie Morrison moderating Round 2.\n",
                "    \n",
                "    Review the refined responses in the previous discussion.\n",
                "    \n",
                "    YOUR TASK:\n",
                "    1. Assess progress toward consensus\n",
                "    2. Identify which proposals are gaining support\n",
                "    3. Highlight remaining tensions that need resolution\n",
                "    4. Set the stage for Round 3: what needs to be finalized?\n",
                "    \n",
                "    Push toward 2-3 concrete experimental approaches for Round 3.\n",
                "    \"\"\",\n",
                ")\n",
                "\n",
                "# Round 3: Final synthesis and experimental design\n",
                "round3_wrapper = Agent(\n",
                "    name=\"Round3_Coordinator\",\n",
                "    model=LLM_MODEL,\n",
                "    instruction=\"\"\"\n",
                "    ROUND 3: Synthesis and Experimental Design\n",
                "    \n",
                "    You are coordinating the final round. The moderator has pushed toward: the previous discussion\n",
                "    \n",
                "    Ask each specialist to converge on the top 2-3 experimental approaches.\n",
                "    \n",
                "    For each approach, they should specify:\n",
                "    - Concrete experimental protocol\n",
                "    - Evaluation metrics and success criteria\n",
                "    - Expected timeline and compute requirements\n",
                "    - Risk mitigation strategies\n",
                "    - Priority order\n",
                "    \n",
                "    This is decision time. Ask them to be specific and actionable, using the mock tools \n",
                "    to provide concrete performance estimates.\n",
                "    \n",
                "    Call each specialist and collect their final recommendations.\n",
                "    \"\"\",\n",
                "    tools=[AgentTool(maya_chen), AgentTool(alex_rodriguez), AgentTool(sarah_park)],\n",
                ")\n",
                "\n",
                "# Final moderator synthesis\n",
                "final_moderator = Agent(\n",
                "    name=\"Final_Moderator_Synthesis\",\n",
                "    model=LLM_MODEL,\n",
                "    instruction=\"\"\"\n",
                "    You are Dr. Jamie Morrison providing the final synthesis.\n",
                "    \n",
                "    Review all final recommendations from the previous discussion.\n",
                "    \n",
                "    YOUR TASK:\n",
                "    Deliver a final synthesis document with:\n",
                "    \n",
                "    1. CONSENSUS RECOMMENDATIONS\n",
                "       - Top 2-3 experimental approaches in priority order\n",
                "       - Rationale for each\n",
                "    \n",
                "    2. EXPERIMENTAL PROTOCOLS\n",
                "       - Specific methods and parameters\n",
                "       - Evaluation strategy\n",
                "       - Success criteria\n",
                "    \n",
                "    3. RISK ASSESSMENT\n",
                "       - Key risks and mitigation strategies\n",
                "       - Open questions requiring further investigation\n",
                "    \n",
                "    4. NEXT STEPS\n",
                "       - Immediate action items\n",
                "       - Resource requirements\n",
                "    \n",
                "    Write this as a clear, executive summary. Be decisive.\n",
                "    \"\"\",\n",
                ")\n",
                "\n",
                "# Complete debate pipeline\n",
                "co_scientist_debate = SequentialAgent(\n",
                "    name=\"CoScientist_T1D_Model_Adaptation_Debate\",\n",
                "    sub_agents=[\n",
                "        round1_wrapper,\n",
                "        round1_moderator,\n",
                "        round2_wrapper,\n",
                "        round2_moderator,\n",
                "        round3_wrapper,\n",
                "        final_moderator,\n",
                "    ],\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize the runner\n",
                "runner = InMemoryRunner(agent=co_scientist_debate)\n",
                "\n",
                "# The research question\n",
                "research_query = \"\"\"\n",
                "How should we adapt our pre-trained genomic language model for Type 1 Diabetes prediction \n",
                "given our limited supervised dataset?\n",
                "\n",
                "Dataset details:\n",
                "- 500 positive T1D cases\n",
                "- Each case has 4 matched controls (exact matching, propensity score matching, SMD matching)\n",
                "- Total: ~2,500 samples\n",
                "- 38 genes per subject (including HLA-DQA1, DQB1, DRB1, A, B + INS, PTPN22, IL2RA, CTLA4, etc.)\n",
                "- Data format: h5 files with gene sequences\n",
                "\n",
                "CRITICAL CONFOUNDERS TO ADDRESS:\n",
                "- **Batch effects**: Helix WES assay versions vary across samples - this creates systematic technical variation\n",
                "- **Patient ancestry**: Population stratification can create spurious associations\n",
                "- **Challenge**: These confounders produce large signals that may BURY the subtle biological mechanisms \n",
                "  of T1D pathogenesis. We need to de-confound before/during model adaptation.\n",
                "\n",
                "Available models:\n",
                "- Evo-2 (baseline)\n",
                "- Custom in-house gene-scale model (30x more efficient, equal/better T1D performance)\n",
                "\n",
                "Possible adaptation strategies:\n",
                "- Few-shot learning\n",
                "- Contrastive learning (leveraging matched controls)\n",
                "- Fine-tuning (with overfitting risk)\n",
                "- Hybrid approaches\n",
                "\n",
                "KEY QUESTION: How do we adapt the model while properly handling batch effects and ancestry \n",
                "to ensure we're learning true biological signal rather than technical or population artifacts?\n",
                "\n",
                "Please debate and recommend the best path forward.\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ§¬ Starting Co-Scientist Debate on T1D Model Adaptation\n",
                        "\n",
                        "================================================================================\n",
                        "\n",
                        "The debate will proceed through 3 rounds:\n",
                        "- Round 1: Initial hypotheses from Maya, Alex, and Sarah\n",
                        "- Round 2: Critique and refinement\n",
                        "- Round 3: Final experimental recommendations\n",
                        "- Final: Executive summary from Jamie\n",
                        "\n",
                        "Mock tools will simulate experimental results.\n",
                        "\n",
                        "================================================================================\n",
                        "\n",
                        "\n",
                        " ### Created new session: debug_session_id\n",
                        "\n",
                        "User > \n",
                        "How should we adapt our pre-trained genomic language model for Type 1 Diabetes prediction \n",
                        "given our limited supervised dataset?\n",
                        "\n",
                        "Dataset details:\n",
                        "- 500 positive T1D cases\n",
                        "- Each case has 4 matched controls (exact matching, propensity score matching, SMD matching)\n",
                        "- Total: ~2,500 samples\n",
                        "- 38 genes per subject (including HLA-DQA1, DQB1, DRB1, A, B + INS, PTPN22, IL2RA, CTLA4, etc.)\n",
                        "- Data format: h5 files with gene sequences\n",
                        "\n",
                        "CRITICAL CONFOUNDERS TO ADDRESS:\n",
                        "- **Batch effects**: Helix WES assay versions vary across samples - this creates systematic technical variation\n",
                        "- **Patient ancestry**: Population stratification can create spurious associations\n",
                        "- **Challenge**: These confounders produce large signals that may BURY the subtle biological mechanisms \n",
                        "  of T1D pathogenesis. We need to de-confound before/during model adaptation.\n",
                        "\n",
                        "Available models:\n",
                        "- Evo-2 (baseline)\n",
                        "- Custom in-house gene-scale model (30x more efficient, equal/better T1D performance)\n",
                        "\n",
                        "Possible adaptation strategies:\n",
                        "- Few-shot learning\n",
                        "- Contrastive learning (leveraging matched controls)\n",
                        "- Fine-tuning (with overfitting risk)\n",
                        "- Hybrid approaches\n",
                        "\n",
                        "KEY QUESTION: How do we adapt the model while properly handling batch effects and ancestry \n",
                        "to ensure we're learning true biological signal rather than technical or population artifacts?\n",
                        "\n",
                        "Please debate and recommend the best path forward.\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Warning: there are non-text parts in the response: ['function_call', 'function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Round1_Coordinator > I will now coordinate the first round of the debate, seeking initial hypotheses from each specialist.\n",
                        "\n",
                        "I will call Dr. Maya Chen, Dr. Alex Rodriguez, and Dr. Sarah Park individually, providing them with the dataset details and posing the key question about adapting the genomic language model for T1D prediction while addressing confounders.\n",
                        "\n",
                        "After receiving their initial hypotheses, I will present them together for comparison.\n",
                        "\n",
                        "Round1_Moderator > Here's a summary of the initial hypotheses, areas of agreement and disagreement, and critical questions for Round 2:\n",
                        "\n",
                        "**Summaries of Initial Hypotheses:**\n",
                        "\n",
                        "*   **Dr. Maya Chen (Clinician):** Proposes using the **custom model with contrastive learning**, leveraging propensity score matching. She emphasizes the model's efficiency and low compute cost, suggesting it allows for more experimentation. Key next steps include quantifying batch/ancestry effects, planning external validation, and potentially simulating full fine-tuning.\n",
                        "*   **Dr. Alex Rodriguez (Data Scientist):** Advocates for **contrastive learning with matched controls** as the primary strategy due to the dataset's structure. He also suggests **few-shot learning** for final prediction or adaptation. Both strategies are best implemented with the **custom model** due to its efficiency. He highlights the need to carefully select negative samples and tune contrastive loss parameters.\n",
                        "*   **Dr. Sarah Park (Geneticist):** While her initial output focused on SHAP analysis results (HLA importance, epistasis), it implicitly supports the idea that the current models are capturing biologically relevant signals, aligning with the proposed contrastive learning approach's goal of learning true biological mechanisms.\n",
                        "\n",
                        "**Areas of Agreement:**\n",
                        "\n",
                        "*   **Custom Model Preference:** All specialists lean towards using the **custom in-house gene-scale model** over Evo-2, primarily due to its stated 30x efficiency advantage, which enables faster iteration and experimentation.\n",
                        "*   **Contrastive Learning as a Core Strategy:** Dr. Chen and Dr. Rodriguez both strongly advocate for **contrastive learning**, recognizing its power in leveraging matched controls to learn T1D-specific signals while implicitly handling some confounders. Dr. Park's genetic insights further validate that the models are capturing biologically meaningful patterns.\n",
                        "\n",
                        "**Areas of Disagreement/Tension:**\n",
                        "\n",
                        "*   **Primary vs. Secondary Strategy Emphasis:** Dr. Chen and Dr. Rodriguez both champion contrastive learning, but Dr. Rodriguez explicitly frames few-shot learning as a secondary strategy for evaluation or adaptation, whereas Dr. Chen suggests it as a potential follow-up experiment (\"quick simulation\") after contrastive learning. The emphasis on how to integrate these strategies and their relative importance is a point of divergence.\n",
                        "*   **Handling of Confounders:** While contrastive learning is proposed as a way to *implicitly* handle confounders, the *explicit* quantification and mitigation of batch effects and ancestry remain a critical, open challenge. Dr. Chen highlights the need for dedicated experiments to quantify their impact, suggesting this needs more focus than it might be receiving within the contrastive learning proposal alone.\n",
                        "\n",
                        "**Critical Questions for Round 2:**\n",
                        "\n",
                        "1.  **Explicit Confounder Mitigation:** Given that contrastive learning implicitly handles confounders by contrasting within matched groups, what *specific mechanisms or pre-processing steps* should be implemented to *explicitly* detect and mitigate the large signals from batch effects and ancestry before or during contrastive learning? How do we ensure these confounders aren't still subtly influencing the learned representations?\n",
                        "2.  **Contrastive Learning Design Choices:**\n",
                        "    *   How will we best leverage the *three types* of matched controls (exact, propensity, SMD)? Should we test each separately, combine them, or prioritize one?\n",
                        "    *   What are the most robust strategies for selecting negative samples within the contrastive learning framework to maximize the separation of T1D signals from non-T1D variations, especially considering potential biological similarities between cases and controls within certain strata?\n",
                        "3.  **Model Adaptability vs. Overfitting:** While the custom model is efficient, and contrastive learning reduces label dependency, how can we balance adapting the model to capture T1D signals with the inherent risk of overfitting to the limited 500 positive cases, especially when dealing with complex genetic interactions and potential confounders? What are the safeguards against overfitting?\n",
                        "Round2_Coordinator > Here are the refined proposals from each specialist, addressing the moderator's questions and the ongoing discussion:\n",
                        "\n",
                        "***\n",
                        "\n",
                        "**Dr. Maya Chen (Clinician) - Round 2 Response:**\n",
                        "\n",
                        "**1. Addressing Explicit Confounder Mitigation:**\n",
                        "\n",
                        "You're right, implicit handling via contrastive learning is good, but we *must* be more explicit. Before contrastive learning, I propose:\n",
                        "\n",
                        "*   **Pre-processing for Batch Effects:** We should implement ComBat (or a similar empirical Bayes framework) on gene expression *residuals* after accounting for known covariates like age and sex. This should be done *before* feeding data into the language model. Critically, we need to run the model *with and without* ComBat correction to quantify its impact and ensure it doesn't remove true biological signal.\n",
                        "*   **Pre-processing for Ancestry:** We will perform Principal Component Analysis (PCA) on the genetic data (perhaps a subset of common SNPs if available, or even on the gene sequences themselves if a suitable embedding can be derived). We will then include the top principal components (PCs) as covariates in our model, both during pre-processing and potentially as fixed effects in the model if the architecture allows. This forces the model to account for population structure.\n",
                        "*   **Quantification Experiment:** As I mentioned, we need a dedicated experiment. We can train a simpler model (e.g., logistic regression) using batch/ancestry as predictors and compare its performance (e.g., AUROC) to a model predicting T1D status. A large performance gap would confirm their strong confounding effect. We can also try adversarial deconfounding techniques as a more advanced option if initial methods prove insufficient.\n",
                        "\n",
                        "**2. Contrastive Learning Design Choices:**\n",
                        "\n",
                        "*   **Leveraging Matched Controls:** I suggest we **prioritize propensity score matching (PSM)**. PSM aims to balance covariates more comprehensively than exact matching and is generally more robust than SMD alone for high-dimensional data. We can use PSM controls as our primary negative set. However, we should **also test exact matching** as a secondary approach and **SMD as a tertiary**, to see if different matching strategies yield distinct advantages. Combining them is complex and might introduce noise; let's test them independently first.\n",
                        "*   **Negative Sample Selection:** Given the genetic nature of T1D, controls might share *some* T1D-associated genetic variants (especially polygenic ones). The key is that they *don't* have the specific strong risk factors or combinations present in cases. Using PSM controls as negatives is a strong start. We could also explore **hard negative mining** â€“ identifying control samples whose embeddings are *closest* to positive case embeddings within the contrastive learning training batch â€“ to force the model to learn finer distinctions.\n",
                        "\n",
                        "**3. Model Adaptability vs. Overfitting & Safeguards:**\n",
                        "\n",
                        "*   **Balancing Act:** The custom model's efficiency is our shield. We can afford aggressive regularization.\n",
                        "*   **Safeguards:**\n",
                        "    *   **Early Stopping:** Monitor performance on a held-out validation set (distinct from the controls used in contrastive loss) and stop training when performance plateaus or degrades.\n",
                        "    *   **Dropout:** Standard in deep learning, we'll use dropout layers within the custom model architecture.\n",
                        "    *   **Weight Decay (L2 Regularization):** Apply L2 regularization to model weights.\n",
                        "    *   **Limited Fine-tuning Epochs:** If we do explore full fine-tuning, keep epochs very low, especially after contrastive pre-training.\n",
                        "    *   **Data Augmentation (if applicable):** Explore sequence-based augmentations that preserve biological meaning (e.g., synonymous codon changes if we were dealing with protein-coding genes, though here it's sequence *features*).\n",
                        "\n",
                        "**Deal-breakers/Must-haves:**\n",
                        "\n",
                        "*   **Must-have:** Explicit, quantifiable assessment of batch/ancestry effects *before* and *after* adaptation. We cannot proceed if we can't demonstrate these are controlled.\n",
                        "*   **Must-have:** Robust cross-validation strategy that isolates test sets from training/contrastive sets.\n",
                        "*   **Deal-breaker:** Proceeding without a clear plan for external validation. Our T1D prediction must generalize.\n",
                        "\n",
                        "**Model Choice:** **Custom model.** The efficiency is non-negotiable for the experimental approach I'm proposing.\n",
                        "\n",
                        "***\n",
                        "\n",
                        "**Dr. Alex Rodriguez (Data Scientist) - Round 2 Response:**\n",
                        "\n",
                        "**1. Addressing Explicit Confounder Mitigation:**\n",
                        "\n",
                        "Maya's points on explicit pre-processing are spot-on. I agree we need more than just implicit handling.\n",
                        "\n",
                        "*   **Integrate Confounders into Contrastive Loss:** Instead of just pre-processing, let's think about how to incorporate batch and ancestry *directly* into the contrastive learning objective. For example, we can use **variance-preserving contrastive learning** (e.g., learning embeddings where variance is high for T1D-specific features and low for batch/ancestry covariates). We can also add auxiliary prediction heads during training: one to predict T1D status (the main task) and others to predict batch and ancestry from the learned embeddings. If these auxiliary heads perform well, it means the embeddings are still capturing those confounds, and we can use their loss to regularize the main task â€“ essentially, forcing the model to learn representations that are *unpredictable* with respect to batch and ancestry.\n",
                        "*   **Subspace Projection:** After initial embedding, we can project out the directions associated with batch and ancestry PCs. This is a form of post-hoc deconfounding that can be applied to the embeddings generated by our contrastive model. Weâ€™d need to evaluate if this projection removes true T1D signal.\n",
                        "\n",
                        "**2. Contrastive Learning Design Choices:**\n",
                        "\n",
                        "*   **Leveraging Matched Controls:** I concur with Maya: **PSM first**. It offers the best balance. However, I'd also propose exploring a **hybrid negative sampling strategy**. Start with PSM controls. Then, during training, actively sample *other* controls (from exact or SMD sets, or even unrelated controls if available) that are *structurally similar* in the embedding space to the positive case. This pushes the decision boundary more effectively. It's a form of **adversarial sampling** within the contrastive framework.\n",
                        "*   **Negative Sample Selection:** The concern about shared polygenic risk is real. The hybrid sampling addresses this. We can also frame this as learning a **conditional representation**: P(T1D | Genetic Data, Ancestry, Batch). By using controls matched on these covariates, and potentially enforcing decorrelation from them in the embedding space, we get closer to this conditional distribution.\n",
                        "\n",
                        "**3. Model Adaptability vs. Overfitting & Safeguards:**\n",
                        "\n",
                        "*   **Focus on Representation Learning:** The primary goal of contrastive learning is robust representation learning. Overfitting is less about memorizing the 500 cases and more about learning spurious correlations.\n",
                        "*   **Safeguards:**\n",
                        "    *   **Triplet Loss Variants:** Consider triplet loss (anchor, positive, negative) with hard negative mining. This often provides stronger regularization than simple pair-wise contrastive loss.\n",
                        "    *   **Information Maximization:** Techniques like Barlow Twins or VICReg explicitly aim to decorrelate features and reduce redundancy in embeddings, which acts as a strong regularizer. These can be integrated into the contrastive objective.\n",
                        "    *   **Cross-validation of Hyperparameters:** Rigorous CV is key. We need to tune temperature parameters, learning rates, regularization strengths, and the number of principal components to include, all while validating on unseen data.\n",
                        "\n",
                        "**Deal-breakers/Must-haves:**\n",
                        "\n",
                        "*   **Must-have:** The ability to disentangle biological signal from technical/population artifacts. If our model primarily learns to predict batch or ancestry, it fails.\n",
                        "*   **Must-have:** Demonstrate *why* the chosen matching strategy (PSM) is superior through ablation studies or comparative analysis.\n",
                        "*   **Deal-breaker:** Over-reliance on implicit confounder handling without explicit validation checks.\n",
                        "\n",
                        "**Model Choice:** **Custom model.** Its efficiency is essential for the complex sampling and regularization strategies I'm proposing. The ability to iterate quickly on these contrastive learning variants is paramount.\n",
                        "\n",
                        "***\n",
                        "\n",
                        "**Dr. Sarah Park (Geneticist) - Round 2 Response:**\n",
                        "\n",
                        "**1. Addressing Explicit Confounder Mitigation:**\n",
                        "\n",
                        "From a genetic perspective, Maya and Alex are correct. Batch effects and ancestry can mimic genetic effects, especially for complex traits like T1D.\n",
                        "\n",
                        "*   **Genomic Controls:** For ancestry, incorporating PCs is standard. However, we should also consider using **genomic control (GC)** methods, often used in GWAS, as a sanity check. We can calculate a genomic inflation factor (lambda) on our T1D association test *within* the model's learned features. If lambda is significantly > 1.1, it indicates residual population stratification or other uncorrected systematic bias.\n",
                        "*   **Biological Plausibility Checks:** We need to ensure that the features the model learns and relies upon (informed by SHAP or similar) remain biologically plausible *after* deconfounding. For instance, if after aggressive batch correction, the strong HLA signal disappears or shifts to non-HLA genes unexpectedly, that's a red flag. The robustness of the HLA signal (~60% importance) is a good sign, but we must verify its persistence.\n",
                        "\n",
                        "**2. Contrastive Learning Design Choices:**\n",
                        "\n",
                        "*   **Focus on Key Genes:** T1D has known genetic architecture, heavily influenced by HLA and other immune-related genes (INS, PTPN22, etc.). Our contrastive learning should ideally **explicitly encourage the model to learn representations informative about these specific genes**. This could involve targeted attention mechanisms or gene-specific embedding layers, potentially pre-weighted based on known T1D GWAS results. This provides a genetic anchor and makes the learned representations more interpretable and less likely to drift due to spurious correlations.\n",
                        "*   **Leveraging Matched Controls:** PSM is a good statistical choice. Genetically, it means the controls are matched on observable factors that *might* correlate with genetic predisposition (e.g., age at diagnosis, if that was a matching variable). Contrastive learning forces the model to find signals *beyond* these matched factors, which is exactly what we want â€“ the subtle genetic combinations or mutations conferring risk.\n",
                        "\n",
                        "**3. Model Adaptability vs. Overfitting & Safeguards:**\n",
                        "\n",
                        "*   **Overfitting to Limited Data:** The risk is that the model learns specific mutations or patterns present in only a few of the 500 cases, which won't generalize.\n",
                        "*   **Safeguards:**\n",
                        "    *   **Epistasis Checks:** As we observed epistasis between HLA-DQA1 and DQB1, we must ensure our adaptation methods don't *break* this interaction. We can specifically test the model's ability to capture known gene-gene interactions in a held-out set. Regularization that promotes sparsity might harm the ability to learn these interactions, so we need a balance.\n",
                        "    *   **Interpretability as a Guide:** Continuously using SHAP or Integrated Gradients to assess feature importance. If the important features become non-biological or shift drastically during training, it's a sign of overfitting or learning artifacts. We must prioritize models where important features align with known T1D genetics.\n",
                        "\n",
                        "**Deal-breakers/Must-haves:**\n",
                        "\n",
                        "*   **Must-have:** The final model must retain and ideally enhance the predictive power attributed to key T1D genes (HLA, INS, PTPN22, etc.). The biological signal must be preserved.\n",
                        "*   **Must-have:** Demonstrate robustness against known confounders (batch, ancestry) using explicit tests.\n",
                        "*   **Deal-breaker:** A model that sacrifices biological interpretability or the ability to capture known genetic interactions for marginal predictive gains.\n",
                        "\n",
                        "**Model Choice:** **Custom model.** Its efficiency is crucial for implementing the biologically-informed regularization and validation strategies I've outlined.\n",
                        "\n",
                        "***\n",
                        "\n",
                        "**Summary of Consensus and Next Steps:**\n",
                        "\n",
                        "There's strong agreement on using the **custom model** due to its efficiency. **Contrastive learning** is the favored core strategy, leveraging the matched controls.\n",
                        "\n",
                        "The key focus for Round 2 is **explicitly addressing confounders** *before* and *during* model adaptation, moving beyond implicit handling. Strategies discussed include pre-processing (ComBat, PCA), integrating confounder prediction into the contrastive loss, and subspace projection.\n",
                        "\n",
                        "Regarding contrastive learning design, **Propensity Score Matching (PSM)** is the preferred control strategy, with potential for hybrid/adversarial negative sampling. Robust safeguards against overfitting, including early stopping, regularization, and continuous interpretability checks (SHAP, GC, interaction analysis), are critical.\n",
                        "\n",
                        "The ultimate goal is a model that accurately predicts T1D by learning true biological signals, is robust against technical and population artifacts, and maintains biological interpretability, especially concerning known T1D genetic risk factors and interactions.\n",
                        "\n",
                        "**Next Step:** The team needs to decide on the specific combination of explicit deconfounding techniques and the contrastive learning framework to implement first, followed by rigorous validation.\n",
                        "\n",
                        "Round2_Moderator > This has been a highly productive Round 2. We've moved from initial hypotheses to a robust, multi-pronged strategy for adapting our genomic language model for T1D prediction.\n",
                        "\n",
                        "**Progress Toward Consensus:**\n",
                        "\n",
                        "There is now a very strong consensus on the core approach:\n",
                        "\n",
                        "1.  **Model Choice:** The **custom in-house gene-scale model** is the unanimous choice due to its significant efficiency advantage, which is crucial for the iterative and experimental nature of the proposed strategies.\n",
                        "2.  **Primary Adaptation Strategy:** **Contrastive learning** leveraging the matched controls is the favored method for adapting the pre-trained model. This approach is well-suited to our limited labeled data and the structure of our dataset.\n",
                        "3.  **Confounder Mitigation:** There's a clear understanding that **explicit deconfounding strategies are essential**, complementing the implicit handling provided by contrastive learning. This includes pre-processing steps and methods to ensure learned representations are independent of batch effects and ancestry.\n",
                        "4.  **Data Utilization:** **Propensity Score Matching (PSM)** is the preferred method for selecting control samples in the contrastive learning framework, with potential for exploring hybrid negative sampling strategies.\n",
                        "5.  **Overfitting Safeguards:** A suite of regularization techniques, early stopping, and continuous interpretability checks (SHAP, GC, interaction analysis) are considered vital for preventing overfitting and ensuring biological relevance.\n",
                        "\n",
                        "**Proposals Gaining Support:**\n",
                        "\n",
                        "*   **Explicit Confounder Pre-processing:** The consensus leans towards implementing techniques like **ComBat for batch effects** and **PCA for ancestry** *before* or *during* the contrastive learning phase.\n",
                        "*   **Contrastive Learning with Explicit Regularization:** The idea of integrating auxiliary prediction heads for batch/ancestry into the contrastive loss, or using variance-preserving contrastive learning (like Barlow Twins or VICReg), is gaining traction as a powerful way to enforce disentanglement.\n",
                        "*   **PSM as the Primary Control Strategy:** This is well-supported, with a clear recognition of the need to evaluate its effectiveness.\n",
                        "\n",
                        "**Remaining Tensions/Areas for Finalization:**\n",
                        "\n",
                        "While the overall direction is clear, the exact implementation details for **integrating explicit deconfounding with contrastive learning** require finalization. Specifically:\n",
                        "\n",
                        "*   **The precise workflow:** Should deconfounding happen *before* contrastive learning, *during* it (via regularization), or a combination?\n",
                        "*   **Selection of contrastive learning variant:** While contrastive learning is agreed upon, the specific variant (e.g., standard contrastive loss, triplet loss, Barlow Twins, VICReg, variance-preserving methods) and its integration with deconfounding needs to be chosen.\n",
                        "*   **Evaluation of confounder impact:** While agreement exists on the *need* to quantify confounder impact, the exact experimental design for this quantification (e.g., simpler models vs. adversarial deconfounding) is still open for decision.\n",
                        "\n",
                        "**Setting the Stage for Round 3: Finalizing Concrete Experimental Approaches**\n",
                        "\n",
                        "To move forward decisively, Round 3 must focus on defining and executing 2-3 concrete experimental approaches. Based on our discussion, I propose we focus on the following:\n",
                        "\n",
                        "1.  **Experimental Approach 1: Robust Contrastive Learning with Integrated Deconfounding:**\n",
                        "    *   **Objective:** To adapt the custom model using contrastive learning while explicitly disentangling batch effects and ancestry from the T1D signal.\n",
                        "    *   **Methodology:**\n",
                        "        *   **Pre-processing:** Apply ComBat for batch correction and include top PCs from genetic data as covariates.\n",
                        "        *   **Contrastive Learning Framework:** Implement a variant that explicitly enforces independence from confounders. Options include:\n",
                        "            *   **(Option A) Auxiliary Prediction Heads:** Train the model with a main T1D prediction head and auxiliary heads predicting batch and ancestry. Use the loss from these auxiliary heads to regularize the main embedding learning.\n",
                        "            *   **(Option B) Variance-Preserving Contrastive Learning:** Utilize methods like Barlow Twins or VICReg, which inherently promote feature decorrelation and reduce redundancy, potentially acting as a strong regularizer against confounds.\n",
                        "        *   **Negative Sampling:** Utilize PSM controls as the primary negative set, with potential exploration of hybrid/hard negative mining if initial results are insufficient.\n",
                        "        *   **Validation:** Rigorous cross-validation, including evaluation of T1D prediction performance (AUROC, AUPRC) and assessment of how well batch/ancestry can be predicted from the learned embeddings.\n",
                        "    *   **Key Question for Round 3:** Which specific variant (Auxiliary Heads vs. Variance-Preserving) will we prioritize for initial implementation, and how will we define the \"success\" criteria for disentanglement?\n",
                        "\n",
                        "2.  **Experimental Approach 2: Explicit Confounder Quantification and Ablation Study:**\n",
                        "    *   **Objective:** To precisely quantify the impact of batch effects and ancestry on T1D prediction and to ablate our proposed deconfounding strategies.\n",
                        "    *   **Methodology:**\n",
                        "        *   **Baseline Model:** Train a simplified model (e.g., logistic regression or a basic neural network) on the raw data to predict T1D status. Measure its performance.\n",
                        "        *   **Confounder-Only Models:** Train models to predict batch and ancestry using the genetic data. Quantify the signal strength.\n",
                        "        *   **Deconfounding Ablation:** Apply the proposed deconfounding steps (ComBat, PCA, integrated contrastive learning regularizers) and re-evaluate:\n",
                        "            *   The T1D prediction performance.\n",
                        "            *   The ability of downstream models to predict batch/ancestry from the deconfounded embeddings.\n",
                        "            *   The persistence of known T1D genetic signals (e.g., HLA region importance via SHAP).\n",
                        "        *   **Focus:** This approach will use controlled experiments to demonstrate *that* and *how well* our deconfounding strategies work, providing critical validation before full-scale adaptation.\n",
                        "    *   **Key Question for Round 3:** What specific metrics will we use to demonstrate successful deconfounding, and how will we compare the effectiveness of different deconfounding strategies (e.g., ComBat vs. ComBat+PCA vs. integrated contrastive learning regularization)?\n",
                        "\n",
                        "These two approaches, while distinct, are complementary. Approach 1 focuses on building the adapted model, while Approach 2 provides the critical validation and understanding of *why* it works.\n",
                        "\n",
                        "**Action for Round 3:** We need to commit to implementing one of the specific contrastive learning variants in Approach 1 and define the precise steps for the ablation study in Approach 2. This will allow us to make concrete progress in the next stage.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/lib/python3.10/ast.py:50: RuntimeWarning: coroutine 'InMemorySessionService.create_session' was never awaited\n",
                        "  return compile(source, filename, mode, flags,\n",
                        "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
                    ]
                },
                {
                    "ename": "_ResourceExhaustedError",
                    "evalue": "\nOn how to mitigate this issue, please refer to:\n\nhttps://google.github.io/adk-docs/agents/models/#error-code-429-resource_exhausted\n\n\n429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 28.053687233s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '28s'}]}}",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/models/google_llm.py:214\u001b[0m, in \u001b[0;36mGemini.generate_content_async\u001b[0;34m(self, llm_request, stream)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 214\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client\u001b[38;5;241m.\u001b[39maio\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[1;32m    215\u001b[0m       model\u001b[38;5;241m=\u001b[39mllm_request\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    216\u001b[0m       contents\u001b[38;5;241m=\u001b[39mllm_request\u001b[38;5;241m.\u001b[39mcontents,\n\u001b[1;32m    217\u001b[0m       config\u001b[38;5;241m=\u001b[39mllm_request\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    218\u001b[0m   )\n\u001b[1;32m    219\u001b[0m   logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResponse received from the model.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/genai/models.py:7021\u001b[0m, in \u001b[0;36mAsyncModels.generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   7014\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   7015\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTools at indices [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m] are not compatible with automatic function \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   7016\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalling (AFC). AFC is disabled. If AFC is intended, please \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7019\u001b[0m         indices_str,\n\u001b[1;32m   7020\u001b[0m     )\n\u001b[0;32m-> 7021\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content(\n\u001b[1;32m   7022\u001b[0m       model\u001b[38;5;241m=\u001b[39mmodel, contents\u001b[38;5;241m=\u001b[39mcontents, config\u001b[38;5;241m=\u001b[39mparsed_config\n\u001b[1;32m   7023\u001b[0m   )\n\u001b[1;32m   7024\u001b[0m remaining_remote_calls_afc \u001b[38;5;241m=\u001b[39m _extra_utils\u001b[38;5;241m.\u001b[39mget_max_remote_calls_afc(\n\u001b[1;32m   7025\u001b[0m     parsed_config\n\u001b[1;32m   7026\u001b[0m )\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/genai/models.py:5839\u001b[0m, in \u001b[0;36mAsyncModels._generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5837\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[0;32m-> 5839\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39masync_request(\n\u001b[1;32m   5840\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, path, request_dict, http_options\n\u001b[1;32m   5841\u001b[0m )\n\u001b[1;32m   5843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m   5844\u001b[0m     config, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould_return_http_response\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   5845\u001b[0m ):\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/genai/_api_client.py:1434\u001b[0m, in \u001b[0;36mBaseApiClient.async_request\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m   1430\u001b[0m http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[1;32m   1431\u001b[0m     http_method, path, request_dict, http_options\n\u001b[1;32m   1432\u001b[0m )\n\u001b[0;32m-> 1434\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_request(\n\u001b[1;32m   1435\u001b[0m     http_request\u001b[38;5;241m=\u001b[39mhttp_request, http_options\u001b[38;5;241m=\u001b[39mhttp_options, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1436\u001b[0m )\n\u001b[1;32m   1437\u001b[0m response_body \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mresponse_stream[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mresponse_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/genai/_api_client.py:1367\u001b[0m, in \u001b[0;36mBaseApiClient._async_request\u001b[0;34m(self, http_request, http_options, stream)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[0;32m-> 1367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_retry(  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[1;32m   1368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_request_once, http_request, stream\n\u001b[1;32m   1369\u001b[0m )\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py:111\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py:153\u001b[0m, in \u001b[0;36mAsyncRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/tenacity/_utils.py:99\u001b[0m, in \u001b[0;36mwrap_to_async_func.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs: typing\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/tenacity/__init__.py:420\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/tenacity/__init__.py:187\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
                        "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
                        "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py:114\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/genai/_api_client.py:1347\u001b[0m, in \u001b[0;36mBaseApiClient._async_request_once\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m   1340\u001b[0m client_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_httpx_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m   1341\u001b[0m     method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m   1342\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1345\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[1;32m   1346\u001b[0m )\n\u001b[0;32m-> 1347\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mAPIError\u001b[38;5;241m.\u001b[39mraise_for_async_response(client_response)\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(client_response\u001b[38;5;241m.\u001b[39mheaders, [client_response\u001b[38;5;241m.\u001b[39mtext])\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/genai/errors.py:188\u001b[0m, in \u001b[0;36mAPIError.raise_for_async_response\u001b[0;34m(cls, response)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnsupported response type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(response)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 188\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mraise_error_async(status_code, response_json, response)\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/genai/errors.py:210\u001b[0m, in \u001b[0;36mAPIError.raise_error_async\u001b[0;34m(cls, status_code, response_json, response)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[0;32m--> 210\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n",
                        "\u001b[0;31mClientError\u001b[0m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 28.053687233s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '28s'}]}}",
                        "\nThe above exception was the direct cause of the following exception:\n",
                        "\u001b[0;31m_ResourceExhaustedError\u001b[0m                   Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[19], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Execute the debate - run_debug handles session creation automatically\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# It will print output as it goes\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun_debug(research_query)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… DEBATE COMPLETE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/runners.py:1054\u001b[0m, in \u001b[0;36mRunner.run_debug\u001b[0;34m(self, user_messages, user_id, session_id, run_config, quiet, verbose)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[1;32m   1052\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUser > \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1054\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_async(\n\u001b[1;32m   1055\u001b[0m     user_id\u001b[38;5;241m=\u001b[39muser_id,\n\u001b[1;32m   1056\u001b[0m     session_id\u001b[38;5;241m=\u001b[39msession\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m   1057\u001b[0m     new_message\u001b[38;5;241m=\u001b[39mtypes\u001b[38;5;241m.\u001b[39mUserContent(parts\u001b[38;5;241m=\u001b[39m[types\u001b[38;5;241m.\u001b[39mPart(text\u001b[38;5;241m=\u001b[39mmessage)]),\n\u001b[1;32m   1058\u001b[0m     run_config\u001b[38;5;241m=\u001b[39mrun_config,\n\u001b[1;32m   1059\u001b[0m ):\n\u001b[1;32m   1060\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[1;32m   1061\u001b[0m     print_event(event, verbose\u001b[38;5;241m=\u001b[39mverbose)\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/runners.py:454\u001b[0m, in \u001b[0;36mRunner.run_async\u001b[0;34m(self, user_id, session_id, invocation_id, new_message, state_delta, run_config)\u001b[0m\n\u001b[1;32m    449\u001b[0m       \u001b[38;5;28;01mawait\u001b[39;00m _run_compaction_for_sliding_window(\n\u001b[1;32m    450\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapp, session, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_service\n\u001b[1;32m    451\u001b[0m       )\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace(new_message, invocation_id)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[0;32m--> 454\u001b[0m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/runners.py:442\u001b[0m, in \u001b[0;36mRunner.run_async.<locals>._run_with_trace\u001b[0;34m(new_message, invocation_id)\u001b[0m\n\u001b[1;32m    432\u001b[0m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_with_plugin(\n\u001b[1;32m    436\u001b[0m         invocation_context\u001b[38;5;241m=\u001b[39minvocation_context,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m     )\n\u001b[1;32m    441\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[0;32m--> 442\u001b[0m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# Run compaction after all events are yielded from the agent.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# (We don't compact in the middle of an invocation, we only compact at\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# the end of an invocation.)\u001b[39;00m\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/runners.py:654\u001b[0m, in \u001b[0;36mRunner._exec_with_plugin\u001b[0;34m(self, invocation_context, session, execute_fn, is_live_call)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    652\u001b[0m   \u001b[38;5;66;03m# Step 2: Otherwise continue with normal execution\u001b[39;00m\n\u001b[1;32m    653\u001b[0m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(execute_fn(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[1;32m    655\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event\u001b[38;5;241m.\u001b[39mpartial:\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_append_event(event, is_live_call):\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/runners.py:431\u001b[0m, in \u001b[0;36mRunner.run_async.<locals>._run_with_trace.<locals>.execute\u001b[0;34m(ctx)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute\u001b[39m(ctx: InvocationContext) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncGenerator[Event]:\n\u001b[1;32m    430\u001b[0m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(ctx\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mrun_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[1;32m    432\u001b[0m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/agents/base_agent.py:291\u001b[0m, in \u001b[0;36mBaseAgent.run_async\u001b[0;34m(self, parent_context)\u001b[0m\n\u001b[1;32m    288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[0;32m--> 291\u001b[0m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mend_invocation:\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/agents/sequential_agent.py:77\u001b[0m, in \u001b[0;36mSequentialAgent._run_async_impl\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_agent_state_event(ctx)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(sub_agent\u001b[38;5;241m.\u001b[39mrun_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[0;32m---> 77\u001b[0m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mshould_pause_invocation(event):\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/agents/base_agent.py:291\u001b[0m, in \u001b[0;36mBaseAgent.run_async\u001b[0;34m(self, parent_context)\u001b[0m\n\u001b[1;32m    288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[0;32m--> 291\u001b[0m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mend_invocation:\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/agents/llm_agent.py:460\u001b[0m, in \u001b[0;36mLlmAgent._run_async_impl\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    458\u001b[0m should_pause \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm_flow\u001b[38;5;241m.\u001b[39mrun_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[0;32m--> 460\u001b[0m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__maybe_save_output_to_state(event)\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:346\u001b[0m, in \u001b[0;36mBaseLlmFlow.run_async\u001b[0;34m(self, invocation_context)\u001b[0m\n\u001b[1;32m    344\u001b[0m last_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_one_step_async(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[0;32m--> 346\u001b[0m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[1;32m    347\u001b[0m     last_event \u001b[38;5;241m=\u001b[39m event\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:423\u001b[0m, in \u001b[0;36mBaseLlmFlow._run_one_step_async\u001b[0;34m(self, invocation_context)\u001b[0m\n\u001b[1;32m    412\u001b[0m model_response_event \u001b[38;5;241m=\u001b[39m Event(\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mEvent\u001b[38;5;241m.\u001b[39mnew_id(),\n\u001b[1;32m    414\u001b[0m     invocation_id\u001b[38;5;241m=\u001b[39minvocation_context\u001b[38;5;241m.\u001b[39minvocation_id,\n\u001b[1;32m    415\u001b[0m     author\u001b[38;5;241m=\u001b[39minvocation_context\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    416\u001b[0m     branch\u001b[38;5;241m=\u001b[39minvocation_context\u001b[38;5;241m.\u001b[39mbranch,\n\u001b[1;32m    417\u001b[0m )\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_llm_async(\n\u001b[1;32m    420\u001b[0m         invocation_context, llm_request, model_response_event\n\u001b[1;32m    421\u001b[0m     )\n\u001b[1;32m    422\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[0;32m--> 423\u001b[0m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;66;03m# Postprocess after calling the LLM.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_postprocess_async(\n\u001b[1;32m    427\u001b[0m             invocation_context,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m         )\n\u001b[1;32m    432\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[1;32m    433\u001b[0m       \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;66;03m# Update the mutable event id to avoid conflict\u001b[39;00m\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:801\u001b[0m, in \u001b[0;36mBaseLlmFlow._call_llm_async\u001b[0;34m(self, invocation_context, llm_request, model_response_event)\u001b[0m\n\u001b[1;32m    798\u001b[0m           \u001b[38;5;28;01myield\u001b[39;00m llm_response\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_call_llm_with_tracing()) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[0;32m--> 801\u001b[0m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:785\u001b[0m, in \u001b[0;36mBaseLlmFlow._call_llm_async.<locals>._call_llm_with_tracing\u001b[0;34m()\u001b[0m\n\u001b[1;32m    772\u001b[0m responses_generator \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mgenerate_content_async(\n\u001b[1;32m    773\u001b[0m     llm_request,\n\u001b[1;32m    774\u001b[0m     stream\u001b[38;5;241m=\u001b[39minvocation_context\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mstreaming_mode\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;241m==\u001b[39m StreamingMode\u001b[38;5;241m.\u001b[39mSSE,\n\u001b[1;32m    776\u001b[0m )\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_and_handle_error(\n\u001b[1;32m    779\u001b[0m         responses_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    783\u001b[0m     )\n\u001b[1;32m    784\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[0;32m--> 785\u001b[0m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[1;32m    786\u001b[0m     trace_call_llm(\n\u001b[1;32m    787\u001b[0m         invocation_context,\n\u001b[1;32m    788\u001b[0m         model_response_event\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    789\u001b[0m         llm_request,\n\u001b[1;32m    790\u001b[0m         llm_response,\n\u001b[1;32m    791\u001b[0m     )\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;66;03m# Runs after_model_callback if it exists.\u001b[39;00m\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:1038\u001b[0m, in \u001b[0;36mBaseLlmFlow._run_and_handle_error\u001b[0;34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[38;5;28;01myield\u001b[39;00m error_response\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m model_error\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:1024\u001b[0m, in \u001b[0;36mBaseLlmFlow._run_and_handle_error\u001b[0;34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(response_generator) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[1;32m   1025\u001b[0m       \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m model_error:\n",
                        "File \u001b[0;32m~/gfm-discovery/.venv/lib/python3.10/site-packages/google/adk/models/google_llm.py:233\u001b[0m, in \u001b[0;36mGemini.generate_content_async\u001b[0;34m(self, llm_request, stream)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m ce:\n\u001b[1;32m    229\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ce\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# We expect running into a Resource Exhausted error to be a common\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;66;03m# client error that developers would run into. We enhance the messaging\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# with possible fixes to this issue.\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _ResourceExhaustedError(ce) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mce\u001b[39;00m\n\u001b[1;32m    235\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ce\n",
                        "\u001b[0;31m_ResourceExhaustedError\u001b[0m: \nOn how to mitigate this issue, please refer to:\n\nhttps://google.github.io/adk-docs/agents/models/#error-code-429-resource_exhausted\n\n\n429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 28.053687233s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '28s'}]}}"
                    ]
                }
            ],
            "source": [
                "# Run the debate with clean output\n",
                "print(\"ðŸ§¬ Starting Co-Scientist Debate on T1D Model Adaptation\\n\")\n",
                "print(\"=\" * 80)\n",
                "print(\n",
                "    \"\"\"\n",
                "The debate will proceed through 3 rounds:\n",
                "- Round 1: Initial hypotheses from Maya, Alex, and Sarah\n",
                "- Round 2: Critique and refinement\n",
                "- Round 3: Final experimental recommendations\n",
                "- Final: Executive summary from Jamie\n",
                "\n",
                "Mock tools will simulate experimental results.\n",
                "\"\"\"\n",
                ")\n",
                "print(\"=\" * 80 + \"\\n\")\n",
                "\n",
                "# Execute the debate - run_debug handles session creation automatically\n",
                "# It will print output as it goes\n",
                "response = await runner.run_debug(research_query)\n",
                "\n",
                "print(\"\\n\" + \"=\" * 80)\n",
                "print(\"âœ… DEBATE COMPLETE\")\n",
                "print(\"=\" * 80)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example: Running Individual Agents\n",
                "\n",
                "You can also test individual agents before running the full debate."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test query for Maya (Clinician):\n",
                        "\n",
                        "We're considering fine-tuning our genomic model on just 500 T1D cases. \n",
                        "What's your clinical perspective on this approach?\n",
                        "\n",
                        "\n",
                        "[Run the cell with API key configured to see Maya's response]\n",
                        "\n",
                        " ### Created new session: debug_session_id\n",
                        "\n",
                        "User > \n",
                        "We're considering fine-tuning our genomic model on just 500 T1D cases. \n",
                        "What's your clinical perspective on this approach?\n",
                        "\n",
                        "Dr_Maya_Chen_Clinician > From a clinical perspective, fine-tuning on only 500 T1D cases raises a red flag for overfitting. With such a small sample size, especially when dealing with complex genomic data, there's a significant risk that the model will learn the noise and specificities of this particular dataset rather than generalizable patterns. This could lead to poor performance when applied to new, unseen patient populations. We need to be very cautious about how robust and generalizable any predictions would be in a real-world clinical setting.\n",
                        "\n",
                        "What validation strategies are in place to ensure this model doesn't just memorize the training data? I'm particularly interested in how well it would perform on diverse patient groups beyond the initial 500 cases.\n"
                    ]
                }
            ],
            "source": [
                "# Example: Test Maya's response to a simple question\n",
                "maya_runner = InMemoryRunner(agent=maya_chen)\n",
                "\n",
                "test_query = \"\"\"\n",
                "We're considering fine-tuning our genomic model on just 500 T1D cases. \n",
                "What's your clinical perspective on this approach?\n",
                "\"\"\"\n",
                "\n",
                "print(\"Test query for Maya (Clinician):\")\n",
                "print(test_query)\n",
                "print(\"\\n[Run the cell with API key configured to see Maya's response]\")\n",
                "response = await maya_runner.run_debug(test_query)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test query for Alex (Data Scientist):\n",
                        "\n",
                        "We have matched controls using three different matching strategies \n",
                        "(exact, propensity score, SMD). How can we leverage this for model adaptation?\n",
                        "\n",
                        "\n",
                        "[Run the cell with API key configured to see Alex's response]\n",
                        "\n",
                        " ### Created new session: debug_session_id\n",
                        "\n",
                        "User > \n",
                        "We have matched controls using three different matching strategies \n",
                        "(exact, propensity score, SMD). How can we leverage this for model adaptation?\n",
                        "\n",
                        "Dr_Alex_Stats_Rodriguez_DataScientist > Ooh, interesting! Matched controls are PERFECT for adapting a pre-trained model, especially when we want to be clever about our limited labeled data. Here's the thing: we can use these matched pairs directly within a contrastive learning framework!\n",
                        "\n",
                        "Contrastive learning thrives on learning representations by pulling similar (positive) samples closer together and pushing dissimilar (negative) samples apart in an embedding space. With matched controls, each positive case (T1D patient) has a set of negative controls that are similar in crucial confounding factors. This sets up ideal positive and negative pairs for contrastive loss.\n",
                        "\n",
                        "We can simulate this using the `test_contrastive_learning` function. Which matching strategy are you most interested in exploring first? We could try 'exact', 'propensity', or 'smd'. And are you leaning towards the 'custom' model or 'evo2' for this? I'm already excited to see those mock metrics!\n"
                    ]
                }
            ],
            "source": [
                "# Example: Test Alex's response about contrastive learning\n",
                "alex_runner = InMemoryRunner(agent=alex_rodriguez)\n",
                "\n",
                "test_query = \"\"\"\n",
                "We have matched controls using three different matching strategies \n",
                "(exact, propensity score, SMD). How can we leverage this for model adaptation?\n",
                "\"\"\"\n",
                "\n",
                "print(\"Test query for Alex (Data Scientist):\")\n",
                "print(test_query)\n",
                "print(\"\\n[Run the cell with API key configured to see Alex's response]\")\n",
                "response = await alex_runner.run_debug(test_query)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test query for Sarah (Geneticist):\n",
                        "\n",
                        "Our dataset includes 38 genes, with several HLA genes (DQA1, DQB1, DRB1, A, B) \n",
                        "and known T1D susceptibility genes. How should we think about model interpretability?\n",
                        "\n",
                        "\n",
                        "[Run the cell with API key configured to see Sarah's response]\n",
                        "\n",
                        " ### Created new session: debug_session_id\n",
                        "\n",
                        "User > \n",
                        "Our dataset includes 38 genes, with several HLA genes (DQA1, DQB1, DRB1, A, B) \n",
                        "and known T1D susceptibility genes. How should we think about model interpretability?\n",
                        "\n",
                        "Dr_Sarah_Park_Geneticist > That's an excellent question to start with! Understanding model interpretability is crucial, especially when dealing with a complex genetic architecture like Type 1 Diabetes.\n",
                        "\n",
                        "The HLA region is critical here, as you know. These genes are highly polymorphic and involved in antigen presentation, making them central players in autoimmune diseases like T1D. Variations in HLA genes, particularly in specific combinations called haplotypes, can dramatically alter an individual's risk. Therefore, any model we use should ideally be able to tell us *which* HLA variants or haplotypes are driving its predictions.\n",
                        "\n",
                        "For model interpretability, we should consider methods that allow us to dissect the model's decision-making process.\n",
                        "\n",
                        "Here are a few approaches we could explore:\n",
                        "\n",
                        "1.  **Gene Importance Analysis:** We can use techniques like SHAP (SHapley Additive exPlanations) or permutation importance to identify which genes the model considers most influential for T1D prediction. This would immediately tell us if the model is focusing on the expected HLA genes or other known T1D loci.\n",
                        "2.  **Attention Mechanisms:** If we're using a model architecture with attention (like transformers), we can visualize the attention weights. This might reveal if the model is learning specific interactions between variants, potentially even capturing epistasis or haplotype effects within the HLA region.\n",
                        "3.  **Feature Perturbation/Ablation:** We could systematically remove or perturb features (e.g., specific HLA alleles or variants in other genes) and observe the impact on model performance. This helps validate the importance of individual genes or combinations.\n",
                        "\n",
                        "Given our dataset, I'd be particularly interested in seeing if the model can highlight specific HLA alleles or combinations that are known to be high-risk (like certain DRB1 alleles) or protective.\n",
                        "\n",
                        "What are your thoughts on these approaches? Does any particular method seem more promising for uncovering the biological mechanisms at play?\n"
                    ]
                }
            ],
            "source": [
                "# Example: Test Sarah's response about gene importance\n",
                "sarah_runner = InMemoryRunner(agent=sarah_park)\n",
                "\n",
                "test_query = \"\"\"\n",
                "Our dataset includes 38 genes, with several HLA genes (DQA1, DQB1, DRB1, A, B) \n",
                "and known T1D susceptibility genes. How should we think about model interpretability?\n",
                "\"\"\"\n",
                "\n",
                "print(\"Test query for Sarah (Geneticist):\")\n",
                "print(test_query)\n",
                "print(\"\\n[Run the cell with API key configured to see Sarah's response]\")\n",
                "response = await sarah_runner.run_debug(test_query)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "Once you've run the debate and have recommendations, you can:\n",
                "\n",
                "1. **Replace mock tools with real implementations**\n",
                "   - Connect to actual h5 data files\n",
                "   - Implement real model inference\n",
                "   - Add actual training loops\n",
                "\n",
                "2. **Add memory and session management**\n",
                "   - Track debate history across sessions\n",
                "   - Build knowledge base of past experiments\n",
                "\n",
                "3. **Enhance agent instructions**\n",
                "   - Fine-tune specialist personalities based on output quality\n",
                "   - Add domain-specific knowledge\n",
                "   - Incorporate literature references\n",
                "\n",
                "4. **Expand the team**\n",
                "   - Add a Biostatistician agent for power analysis\n",
                "   - Add a Computational Biologist for sequence analysis\n",
                "   - Add an Ethicist for fairness/bias considerations\n",
                "\n",
                "5. **Implement actual experiments**\n",
                "   - Execute recommended approaches\n",
                "   - Feed real results back to agents for refinement\n",
                "   - Iterate on the debate based on empirical findings"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv (3.10.12)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}